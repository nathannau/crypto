{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install packaging\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from packaging import version\n",
    "import time\n",
    "\n",
    "assert(version.parse(tf.__version__) >= version.parse(\"2.0.0-aplha\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generate_serie(size, step) :\n",
    "    maxT = size*step\n",
    "    t = np.arange(0, maxT, step)\n",
    "#    return (np.sin(t+np.cos(t*0.31))).astype(np.float32)\n",
    "    return (np.sin(t+np.sin(t*.31)) * np.sin(t / 3.3485)).astype(np.float32)\n",
    "#    return (np.sin(t+np.cos(t)) + .34158*np.sin(t * 3.3485)).astype(np.float32)\n",
    "#return (t * np.sin(t)/maxT + .3*np.sin(t * 3.3)).astype(np.float32)\n",
    "\n",
    "def split(arr, *count) :\n",
    "    total = sum(count)\n",
    "    p0 = 0\n",
    "    for i in count :\n",
    "        p1 = p0 + i\n",
    "        yield arr[int(len(arr)*p0/total):int(len(arr)*p1/total)]\n",
    "        p0 = p1\n",
    "    \n",
    "    \n",
    "np.random.seed(42)\n",
    "\n",
    "N_STEPS = n_steps = 50\n",
    "data = generate_serie(14001, .18)\n",
    "data = [(data[i:i+n_steps], data[i+1:i+n_steps+1]) for i in range(len(data)-n_steps-1)] \n",
    "np.random.shuffle(data)\n",
    "\n",
    "#plt.plot(data[1][0])\n",
    "#plt.plot(data[2][0])\n",
    "#plt.plot(data[3][0])\n",
    "#plt.show()\n",
    "\n",
    "spt_data = np.reshape([data[i][0] for i in range(len(data))], (-1, n_steps, 1))\n",
    "spt_lbl = np.reshape([data[i][1] for i in range(len(data))], (-1, n_steps, 1))\n",
    "\n",
    "train_size = 80\n",
    "valid_size = 15\n",
    "test_size = 5\n",
    "\n",
    "[train, valid, test] = zip(split(spt_data, train_size, valid_size, test_size), \n",
    "                           split(spt_lbl, train_size, valid_size, test_size))\n",
    "\n",
    "plt.plot(train[0][1])\n",
    "plt.plot(train[0][2])\n",
    "plt.plot(train[0][3])\n",
    "plt.show()\n",
    "\n",
    "train = tf.data.Dataset.from_tensor_slices((train[0], train[1]))\n",
    "valid = tf.data.Dataset.from_tensor_slices((valid[0], valid[1]))\n",
    "test = tf.data.Dataset.from_tensor_slices((test[0], test[1]))\n",
    "#train = train.batch(64, True)\n",
    "#valid = valid.batch(64, True)\n",
    "#test = test.batch(64, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResetCallback(tf.keras.callbacks.Callback):\n",
    "    def on_batch_begin(self, batch, logs=None) :\n",
    "        print(\"on_batch_begin\")\n",
    "        \n",
    "    def on_batch_end(self, batch, logs=None) :\n",
    "        print(\"on_batch_end\")\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None) :\n",
    "        print(\"on_epoch_begin\")\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None) :\n",
    "        print(\"on_epoch_end\")\n",
    "\n",
    "    def on_predict_batch_begin(self, batch, logs=None) :\n",
    "        print(\"on_predict_batch_begin\")\n",
    "\n",
    "    def on_predict_batch_end(self, batch, logs=None) :\n",
    "        print(\"on_predict_batch_end\")\n",
    "\n",
    "    def on_predict_begin(self, logs=None) :\n",
    "        print(\"on_predict_begin\")\n",
    "\n",
    "    def on_predict_end(self, logs=None) :\n",
    "        print(\"on_predict_end\")\n",
    "\n",
    "    def on_test_batch_begin(self, batch, logs=None) :\n",
    "        print(\"on_test_batch_begin\")\n",
    "        self.model.reset_states()\n",
    "\n",
    "    def on_test_batch_end(self, batch, logs=None) :\n",
    "        print(\"on_test_batch_end\")\n",
    "\n",
    "    def on_test_begin(self, logs=None) :\n",
    "        print(\"on_test_begin\")\n",
    "        self.model.reset_states()\n",
    "\n",
    "    def on_test_end(self, logs=None) :\n",
    "        print(\"on_test_end\")\n",
    "\n",
    "    def on_train_batch_begin(self, batch, logs=None) :\n",
    "        print(\"on_train_batch_begin\")\n",
    "#        self.model.reset_states()\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs=None) :\n",
    "        print(\"on_train_batch_end\")\n",
    "\n",
    "    def on_train_begin(self, logs=None) :\n",
    "        print(\"on_train_begin\")\n",
    "\n",
    "    def on_train_end(self, logs=None) :\n",
    "        print(\"on_train_end\")\n",
    "\n",
    "    def set_model(self, model) :\n",
    "        self.model = model\n",
    "        print(\"set_model\")\n",
    "\n",
    "    def set_params(self, params) :\n",
    "        print(\"set_params\", params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "  def __init__(self, hidden1, enc_units, batch_sz,stateful=True, return_sequences=True) : #, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "    super(Encoder, self).__init__()\n",
    "    self.hidden1 = hidden1\n",
    "    self.enc_units = enc_units\n",
    "    self.batch_sz = batch_sz\n",
    "    #self.input_shape=(50, 1)\n",
    "\n",
    "    #self.stateful = stateful\n",
    "    self.lstm_stateful = stateful\n",
    "    #self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    #self.inputi = tf.keras.Input(shape=(1,))\n",
    "    #self.input_shape = tf.TensorShape([None,1])\n",
    "#    self.d1 = tf.keras.layers.Dense(self.enc_units,\n",
    "#                                    input_shape=(50, 1),\n",
    "#                                    activation=\"linear\")\n",
    "    self.lstm = tf.keras.layers.LSTM(self.hidden1,\n",
    "                                    return_sequences=return_sequences,\n",
    "                                    #return_state=True,\n",
    "                                    stateful=self.lstm_stateful,\n",
    "                                    #activation=\"selu\",\n",
    "                                    #activation=\"linear\",\n",
    "                                    #recurrent_activation=\"selu\",  \n",
    "#                                    input_shape=(50, 1),\n",
    "                                    recurrent_initializer='glorot_uniform')\n",
    "#    self.dense = tf.keras.layers.TimeDistributed(\n",
    "#        tf.keras.layers.Dense(self.enc_units,\n",
    "#                              activation=\"linear\"))\n",
    "    self.dense = tf.keras.layers.Dense(self.enc_units,\n",
    "                                    activation=\"linear\")\n",
    "\n",
    "    #self.gru = tf.keras.layers.RNN(\n",
    "    #    tf.keras.layers.GRUCell(self.enc_units,\n",
    "    #                               recurrent_initializer='glorot_uniform'),\n",
    "    #   return_sequences=True,\n",
    "    #   return_state=True\n",
    "    #)\n",
    "    \n",
    "#  def call(self, x, initial_state=None): #, hidden):\n",
    "  def call(self, x) : #, initial_state=None): #, hidden):\n",
    "    #print(x, initial_state)\n",
    "    #x2 = self.inputi(x)\n",
    "    #print(x2)\n",
    "#    if (initial_state!=None) :\n",
    "#        self.lstm.reset_states(initial_state)\n",
    "    \n",
    "    #self.lstm.reset_states()\n",
    "    #output = self.lstm(x) #, initial_state = hidden)\n",
    "#    x = self.d1(x)\n",
    "    x = self.lstm(x) #, initial_state = hidden)\n",
    "    output = self.dense(x)\n",
    "    #output, self.state = self.lstm(x, self.state) #, initial_state = hidden)\n",
    "    return output #, state\n",
    "\n",
    "  def reset_states(self) :\n",
    "    self.lstm.reset_states()\n",
    "\n",
    "#  def reset_states(self, initial_state=None) :\n",
    "#    #print(self.lstm.input_spec)\n",
    "#    self.lstm.reset_states(initial_state)\n",
    "\n",
    "#  def initialize_hidden_state(self):\n",
    "#    return tf.zeros((self.batch_sz, self.enc_units))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64*8\n",
    "EPOCHS = 4\n",
    "\n",
    "#encoder = keras.models.Sequential([\n",
    "#    keras.layers.LSTM(20, return_sequences=True),\n",
    "#    keras.layers.LSTM(20, return_sequences=True),\n",
    "#    keras.layers.TimeDistributed(keras.layers.Dense(1))\n",
    "#])\n",
    "#print(3, N_STEPS, BATCH_SIZE)\n",
    "encoder = Encoder(10, N_STEPS, BATCH_SIZE, False)\n",
    "encoder.build(tf.TensorShape([BATCH_SIZE, None, 1]))\n",
    "encoder.compile(optimizer=\"Adam\", loss=\"MSE\", metrics=['accuracy'])\n",
    "#encoder.input_shape = tf.TensorShape([BATCH_SIZE, None, 1])\n",
    "#print(encoder.input_shape)\n",
    "encoder.summary()\n",
    "encoder(tf.keras.Input(shape=(50, 1)))\n",
    "print(\"stateful\", encoder.stateful, encoder.state_updates)\n",
    "print(\"encoder\", encoder.input_shape, encoder.output_shape)\n",
    "print(\"lstm\", encoder.lstm.input_shape, encoder.lstm.output_shape)\n",
    "print(\"dense\", encoder.dense.input_shape, encoder.dense.output_shape)\n",
    "\n",
    "encoder = Encoder(10, N_STEPS, BATCH_SIZE, False, return_sequences=False)\n",
    "encoder.build(tf.TensorShape([BATCH_SIZE, None, 1]))\n",
    "encoder.compile(optimizer=\"Adam\", loss=\"MSE\", metrics=['accuracy'])\n",
    "#encoder.input_shape = tf.TensorShape([BATCH_SIZE, None, 1])\n",
    "#print(encoder.input_shape)\n",
    "encoder.summary()\n",
    "encoder(tf.keras.Input(shape=(50, 1)))\n",
    "print(\"stateful\", encoder.stateful, encoder.state_updates)\n",
    "print(\"encoder\", encoder.input_shape, encoder.output_shape)\n",
    "print(\"lstm\", encoder.lstm.input_shape, encoder.lstm.output_shape)\n",
    "print(\"dense\", encoder.dense.input_shape, encoder.dense.output_shape)\n",
    "\n",
    "encoder = Encoder(10, N_STEPS, BATCH_SIZE, True)\n",
    "#encoder = Encoder(1, N_STEPS, BATCH_SIZE)\n",
    "encoder.build(tf.TensorShape([BATCH_SIZE, None, 1]))\n",
    "encoder.summary()\n",
    "encoder.compile(optimizer=\"Adam\", loss=\"MSE\", metrics=['accuracy'])\n",
    "encoder(tf.keras.Input(shape=(50, 1)))\n",
    "print(\"stateful\", encoder.stateful, encoder.state_updates)\n",
    "print(\"encoder\", encoder.input_shape, encoder.output_shape)\n",
    "print(\"lstm\", encoder.lstm.input_shape, encoder.lstm.output_shape)\n",
    "print(\"dense\", encoder.dense.input_shape, encoder.dense.output_shape)\n",
    "\n",
    "encoder = Encoder(10, N_STEPS, BATCH_SIZE, True, return_sequences=False)\n",
    "#encoder = Encoder(1, N_STEPS, BATCH_SIZE)\n",
    "encoder.build(tf.TensorShape([BATCH_SIZE, None, 1]))\n",
    "encoder.summary()\n",
    "encoder.compile(optimizer=\"Adam\", loss=\"MSE\", metrics=['accuracy'])\n",
    "encoder(tf.keras.Input(shape=(50, 1)))\n",
    "print(\"stateful\", encoder.stateful, encoder.state_updates)\n",
    "print(\"encoder\", encoder.input_shape, encoder.output_shape)\n",
    "print(\"lstm\", encoder.lstm.input_shape, encoder.lstm.output_shape)\n",
    "print(\"dense\", encoder.dense.input_shape, encoder.dense.output_shape)\n",
    "\n",
    "#encoder.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.MeanSquaredError())\n",
    "#print(len(train[0]))\n",
    "#print(len(train[0])//BATCH_SIZE)\n",
    "#print(len(train[0])//BATCH_SIZE*BATCH_SIZE)\n",
    "#print(len(valid[0]))\n",
    "#print(len(valid[0])//BATCH_SIZE)\n",
    "#print(len(valid[0])//BATCH_SIZE*BATCH_SIZE)\n",
    "#tbs = len(train[0])//BATCH_SIZE*BATCH_SIZE\n",
    "#vbs = len(valid[0])//BATCH_SIZE*BATCH_SIZE\n",
    "\n",
    "#a = encoder(train[0][:8])\n",
    "#print(a)\n",
    "#history = encoder.fit(train, epochs=EPOCHS) #, batch_size=BATCH_SIZE, shuffle=False)\n",
    "#history = encoder.fit(train[0][:tbs], train[1][:tbs], epochs=EPOCHS, batch_size=BATCH_SIZE)\n",
    "#history = encoder.fit(train.batch(BATCH_SIZE, True), epochs=EPOCHS, validation_data=valid.batch(BATCH_SIZE, True), shuffle=False) # , batch_size=BATCH_SIZE\n",
    "#history = encoder.fit(train.batch(BATCH_SIZE, True), epochs=EPOCHS, validation_data=valid.batch(BATCH_SIZE, True), callbacks=[ResetCallback()], shuffle=False) # , batch_size=BATCH_SIZE\n",
    "#history = encoder.fit(train.batch(64, True), epochs=EPOCHS, validation_data=valid.batch(64, True), callbacks=[ResetCallback()], shuffle=False) # , batch_size=BATCH_SIZE\n",
    "#history = encoder.fit(train[0][:tbs], train[1][:tbs], epochs=EPOCHS, validation_data=(valid[0][:vbs], valid[1][:vbs]), batch_size=BATCH_SIZE)\n",
    "#a = encoder(train[0][:8])\n",
    "#print(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(history)\n",
    "#print(history.history)\n",
    "print(history.history.keys())\n",
    "\n",
    "plt.plot(history.history['loss'], label=\"loss\")\n",
    "plt.plot(history.history['val_loss'], label=\"val_loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.plot(history.history['accuracy'], label=\"accuracy\")\n",
    "plt.plot(history.history['val_accuracy'], label=\"val_accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.evaluate(test.batch(BATCH_SIZE, True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
