{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install packaging\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from packaging import version\n",
    "import time\n",
    "\n",
    "assert(version.parse(tf.__version__) >= version.parse(\"2.0.0-aplha\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def generate_serie(size, step) :\n",
    "    maxT = size*step\n",
    "    t = np.arange(0, maxT, step)\n",
    "#    return (np.sin(t+np.cos(t*0.31))).astype(np.float32)\n",
    "    return (np.sin(t+np.sin(t*.31)) * np.sin(t / 3.3485)).astype(np.float32)\n",
    "#    return (np.sin(t+np.cos(t)) + .34158*np.sin(t * 3.3485)).astype(np.float32)\n",
    "#return (t * np.sin(t)/maxT + .3*np.sin(t * 3.3)).astype(np.float32)\n",
    "\n",
    "def split(arr, *count) :\n",
    "    total = sum(count)\n",
    "    p0 = 0\n",
    "    for i in count :\n",
    "        p1 = p0 + i\n",
    "        yield arr[int(len(arr)*p0/total):int(len(arr)*p1/total)]\n",
    "        p0 = p1\n",
    "    \n",
    "    \n",
    "np.random.seed(42)\n",
    "\n",
    "n_steps = 50\n",
    "data = generate_serie(14001, .18)\n",
    "data = [(data[i:i+n_steps], data[i+1:i+n_steps+1]) for i in range(len(data)-n_steps-1)] \n",
    "np.random.shuffle(data)\n",
    "\n",
    "#plt.plot(data[1][0])\n",
    "#plt.plot(data[2][0])\n",
    "#plt.plot(data[3][0])\n",
    "#plt.show()\n",
    "\n",
    "spt_data = np.reshape([data[i][0] for i in range(len(data))], (-1, n_steps, 1))\n",
    "spt_lbl = np.reshape([data[i][1] for i in range(len(data))], (-1, n_steps, 1))\n",
    "\n",
    "train_size = 80\n",
    "valid_size = 15\n",
    "test_size = 5\n",
    "\n",
    "[train, valid, test] = zip(split(spt_data, train_size, valid_size, test_size), \n",
    "                           split(spt_lbl, train_size, valid_size, test_size))\n",
    "\n",
    "plt.plot(train[0][1])\n",
    "plt.plot(train[0][2])\n",
    "plt.plot(train[0][3])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BATCH_SIZE = 64\n",
    "BATCH_SIZE = 8\n",
    "dataset = tf.data.Dataset.from_tensor_slices((spt_data, spt_lbl))\n",
    "#dataset = tf.data.Dataset.from_tensor_slices(spt_data)\n",
    "#dataset = dataset.batch(BATCH_SIZE, True)\n",
    "#print(dataset.take(64))\n",
    "#for i,(a,b) in enumerate(dataset) : print(\"------\", i, a, b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "  def __init__(self, hidden1, enc_units, batch_sz) : #, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "    super(Encoder, self).__init__()\n",
    "    self.batch_sz = batch_sz\n",
    "    self.hidden1 = hidden1\n",
    "    self.enc_units = enc_units\n",
    "    #self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    #self.inputi = tf.keras.Input(shape=(1,))\n",
    "    #self.input_shape = tf.TensorShape([None,1])\n",
    "    self.lstm = tf.keras.layers.LSTM(self.enc_units,\n",
    "                                    return_sequences=True,\n",
    "                                    #return_state=True,\n",
    "                                    stateful=True,\n",
    "                                    #activation=\"selu\",\n",
    "                                    #activation=\"linear\",\n",
    "                                    #recurrent_activation=\"selu\",  \n",
    "                                    recurrent_initializer='glorot_uniform')\n",
    "    self.dense = tf.keras.layers.Dense(self.enc_units,\n",
    "                                    activation=\"linear\")\n",
    "\n",
    "    #self.gru = tf.keras.layers.RNN(\n",
    "    #    tf.keras.layers.GRUCell(self.enc_units,\n",
    "    #                               recurrent_initializer='glorot_uniform'),\n",
    "    #   return_sequences=True,\n",
    "    #   return_state=True\n",
    "    #)\n",
    "    \n",
    "  def call(self, x, initial_state=None): #, hidden):\n",
    "    #print(x, initial_state)\n",
    "    #x2 = self.inputi(x)\n",
    "    #print(x2)\n",
    "    if (initial_state!=None) :\n",
    "        self.lstm.reset_states(initial_state)\n",
    "    \n",
    "    #output = self.lstm(x) #, initial_state = hidden)\n",
    "    x = self.lstm(x) #, initial_state = hidden)\n",
    "    output = self.dense(x)\n",
    "    #output, self.state = self.lstm(x, self.state) #, initial_state = hidden)\n",
    "    return output #, state\n",
    "\n",
    "  #def reset_states(self) :\n",
    "  #  self.lstm.reset_states()\n",
    "\n",
    "  def reset_states(self, initial_state=None) :\n",
    "    #print(self.lstm.input_spec)\n",
    "    self.lstm.reset_states(initial_state)\n",
    "\n",
    "  def initialize_hidden_state(self):\n",
    "    return tf.zeros((self.batch_sz, self.enc_units))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.MeanSquaredError()\n",
    "mask = np.concatenate((\n",
    "    np.zeros((19,1), dtype=np.float32), \n",
    "    np.ones((1,1), dtype=np.float32)))\n",
    "#print(mask)\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    #print(\"loss_function\")\n",
    "    #mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    #print(real, pred)\n",
    "    real *= mask\n",
    "    pred *= mask\n",
    "    #print(real, pred)\n",
    "    loss_ = loss_object(real, pred)\n",
    "    #print(loss_)\n",
    "\n",
    "    #mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    #loss_ *= mask\n",
    "    #print(loss_)\n",
    "\n",
    "    return tf.reduce_mean(loss_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@tf.function\n",
    "def train_step(model, inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Make a prediction on all the batch\n",
    "        predictions = model(inputs)\n",
    "        # Get the error/loss on these predictions\n",
    "        loss = loss_function(targets, predictions)\n",
    "    # Compute the gradient which respect to the loss\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    # Change the weights of the model\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    # The metrics are accumulate over time. You don't need to average it yourself.\n",
    "    #train_loss(loss)\n",
    "    #train_accuracy(targets, predictions)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "If a RNN is stateful, it needs to know its batch size. Specify the batch size of your input tensors: \n- If using a Sequential model, specify the batch size by passing a `batch_input_shape` argument to your first layer.\n- If using the functional API, specify the batch size by passing a `batch_shape` argument to your Input layer.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-f24d6e8b2011>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Adam\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"MSE\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\.conda\\envs\\tf2Env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    804\u001b[0m         \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    805\u001b[0m         \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 806\u001b[1;33m         shuffle=shuffle)\n\u001b[0m\u001b[0;32m    807\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    808\u001b[0m     \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf2Env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[0;32m   2501\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2502\u001b[0m         \u001b[0mcast_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2503\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2504\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2505\u001b[0m       \u001b[0my_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf2Env\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    455\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 456\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    457\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    458\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf2Env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_set_inputs\u001b[1;34m(self, inputs, outputs, training)\u001b[0m\n\u001b[0;32m   2773\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2774\u001b[0m           \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2775\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2776\u001b[0m           \u001b[1;31m# Reset to the previously saved value. If `call()` had `add_metric`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2777\u001b[0m           \u001b[1;31m# or `add_loss`, then `_contains_symbolic_tensors` will have been set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-54-00a2b8218605>\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, x, initial_state)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;31m#output = self.lstm(x) #, initial_state = hidden)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#, initial_state = hidden)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;31m#output, self.state = self.lstm(x, self.state) #, initial_state = hidden)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf2Env\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 658\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    659\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    660\u001b[0m     \u001b[1;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf2Env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    592\u001b[0m           \u001b[1;31m# Build layer if applicable (if the `build` method has been\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m           \u001b[1;31m# overridden).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 594\u001b[1;33m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    595\u001b[0m           \u001b[1;31m# Explicitly pass the learning phase placeholder to `call` if\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    596\u001b[0m           \u001b[1;31m# the `training` argument was left unspecified by the user.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf2Env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   1711\u001b[0m     \u001b[1;31m# Only call `build` if the user has manually overridden the build method.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1712\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_is_default'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1713\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1714\u001b[0m     \u001b[1;31m# We must set self.built since user defined build functions are not\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1715\u001b[0m     \u001b[1;31m# constrained to set self.built.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf2Env\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    591\u001b[0m       ]\n\u001b[0;32m    592\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    594\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf2Env\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36mreset_states\u001b[1;34m(self, states)\u001b[0m\n\u001b[0;32m    837\u001b[0m       \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    838\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 839\u001b[1;33m       raise ValueError('If a RNN is stateful, it needs to know '\n\u001b[0m\u001b[0;32m    840\u001b[0m                        \u001b[1;34m'its batch size. Specify the batch size '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    841\u001b[0m                        \u001b[1;34m'of your input tensors: \\n'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: If a RNN is stateful, it needs to know its batch size. Specify the batch size of your input tensors: \n- If using a Sequential model, specify the batch size by passing a `batch_input_shape` argument to your first layer.\n- If using the functional API, specify the batch size by passing a `batch_shape` argument to your Input layer."
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 8\n",
    "EPOCHS = 20\n",
    "\n",
    "encoder = Encoder(10, 1, BATCH_SIZE)\n",
    "encoder.compile(optimizer=\"Adam\", loss=\"MSE\")\n",
    "\n",
    "history = encoder.fit(train[0], train[1], epochs=EPOCHS, validation_data=(valid[0], valid[1]), batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder_66\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "unified_lstm_66 (UnifiedLSTM multiple                  12        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  2         \n",
      "=================================================================\n",
      "Total params: 14\n",
      "Trainable params: 14\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1 Batch 0 Loss 0.1105\n",
      "Epoch 1 Batch 10 Loss 0.9168\n",
      "Epoch 1 Batch 20 Loss 1.1438\n",
      "Epoch 1 Loss 1.0294\n",
      "Time taken for 1 epoch 3.2800586223602295 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 0.1011\n",
      "Epoch 2 Batch 10 Loss 0.8864\n",
      "Epoch 2 Batch 20 Loss 1.1720\n",
      "Epoch 2 Loss 1.0178\n",
      "Time taken for 1 epoch 3.1941192150115967 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 0.0982\n",
      "Epoch 3 Batch 10 Loss 0.8764\n",
      "Epoch 3 Batch 20 Loss 1.2012\n",
      "Epoch 3 Loss 1.0152\n",
      "Time taken for 1 epoch 3.7610342502593994 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 0.0959\n",
      "Epoch 4 Batch 10 Loss 0.8673\n",
      "Epoch 4 Batch 20 Loss 1.2055\n",
      "Epoch 4 Loss 1.0111\n",
      "Time taken for 1 epoch 3.2970211505889893 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 0.0942\n",
      "Epoch 5 Batch 10 Loss 0.8587\n",
      "Epoch 5 Batch 20 Loss 1.1985\n",
      "Epoch 5 Loss 1.0049\n",
      "Time taken for 1 epoch 3.1867480278015137 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.0924\n",
      "Epoch 6 Batch 10 Loss 0.8458\n",
      "Epoch 6 Batch 20 Loss 1.1894\n",
      "Epoch 6 Loss 0.9962\n",
      "Time taken for 1 epoch 3.1202924251556396 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.0900\n",
      "Epoch 7 Batch 10 Loss 0.8259\n",
      "Epoch 7 Batch 20 Loss 1.1792\n",
      "Epoch 7 Loss 0.9839\n",
      "Time taken for 1 epoch 3.097433090209961 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.0867\n",
      "Epoch 8 Batch 10 Loss 0.7982\n",
      "Epoch 8 Batch 20 Loss 1.1681\n",
      "Epoch 8 Loss 0.9676\n",
      "Time taken for 1 epoch 4.016702651977539 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.0823\n",
      "Epoch 9 Batch 10 Loss 0.7637\n",
      "Epoch 9 Batch 20 Loss 1.1560\n",
      "Epoch 9 Loss 0.9482\n",
      "Time taken for 1 epoch 3.1267573833465576 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.0770\n",
      "Epoch 10 Batch 10 Loss 0.7256\n",
      "Epoch 10 Batch 20 Loss 1.1417\n",
      "Epoch 10 Loss 0.9268\n",
      "Time taken for 1 epoch 3.2085959911346436 sec\n",
      "\n",
      "Epoch 11 Batch 0 Loss 0.0710\n",
      "Epoch 11 Batch 10 Loss 0.6873\n",
      "Epoch 11 Batch 20 Loss 1.1244\n",
      "Epoch 11 Loss 0.9041\n",
      "Time taken for 1 epoch 3.121744155883789 sec\n",
      "\n",
      "Epoch 12 Batch 0 Loss 0.0644\n",
      "Epoch 12 Batch 10 Loss 0.6514\n",
      "Epoch 12 Batch 20 Loss 1.0999\n",
      "Epoch 12 Loss 0.8786\n",
      "Time taken for 1 epoch 3.2666988372802734 sec\n",
      "\n",
      "Epoch 13 Batch 0 Loss 0.0568\n",
      "Epoch 13 Batch 10 Loss 0.6200\n",
      "Epoch 13 Batch 20 Loss 1.0491\n",
      "Epoch 13 Loss 0.8421\n",
      "Time taken for 1 epoch 3.8390438556671143 sec\n",
      "\n",
      "Epoch 14 Batch 0 Loss 0.0474\n",
      "Epoch 14 Batch 10 Loss 0.5947\n",
      "Epoch 14 Batch 20 Loss 0.9239\n",
      "Epoch 14 Loss 0.7718\n",
      "Time taken for 1 epoch 3.148379325866699 sec\n",
      "\n",
      "Epoch 15 Batch 0 Loss 0.0347\n",
      "Epoch 15 Batch 10 Loss 0.5775\n",
      "Epoch 15 Batch 20 Loss 0.6680\n",
      "Epoch 15 Loss 0.6488\n",
      "Time taken for 1 epoch 3.24306583404541 sec\n",
      "\n",
      "Epoch 16 Batch 0 Loss 0.0244\n",
      "Epoch 16 Batch 10 Loss 0.5670\n",
      "Epoch 16 Batch 20 Loss 0.3486\n",
      "Epoch 16 Loss 0.5223\n",
      "Time taken for 1 epoch 3.0968005657196045 sec\n",
      "\n",
      "Epoch 17 Batch 0 Loss 0.0243\n",
      "Epoch 17 Batch 10 Loss 0.5604\n",
      "Epoch 17 Batch 20 Loss 0.1369\n",
      "Epoch 17 Loss 0.4493\n",
      "Time taken for 1 epoch 3.301309108734131 sec\n",
      "\n",
      "Epoch 18 Batch 0 Loss 0.0224\n",
      "Epoch 18 Batch 10 Loss 0.5552\n",
      "Epoch 18 Batch 20 Loss 0.0572\n",
      "Epoch 18 Loss 0.4011\n",
      "Time taken for 1 epoch 3.8161208629608154 sec\n",
      "\n",
      "Epoch 19 Batch 0 Loss 0.0197\n",
      "Epoch 19 Batch 10 Loss 0.5498\n",
      "Epoch 19 Batch 20 Loss 0.0374\n",
      "Epoch 19 Loss 0.3626\n",
      "Time taken for 1 epoch 3.0810627937316895 sec\n",
      "\n",
      "Epoch 20 Batch 0 Loss 0.0182\n",
      "Epoch 20 Batch 10 Loss 0.5434\n",
      "Epoch 20 Batch 20 Loss 0.0346\n",
      "Epoch 20 Loss 0.3350\n",
      "Time taken for 1 epoch 3.4974734783172607 sec\n",
      "\n",
      "Epoch 21 Batch 0 Loss 0.0176\n",
      "Epoch 21 Batch 10 Loss 0.5354\n",
      "Epoch 21 Batch 20 Loss 0.0346\n",
      "Epoch 21 Loss 0.3169\n",
      "Time taken for 1 epoch 3.5588138103485107 sec\n",
      "\n",
      "Epoch 22 Batch 0 Loss 0.0172\n",
      "Epoch 22 Batch 10 Loss 0.5258\n",
      "Epoch 22 Batch 20 Loss 0.0340\n",
      "Epoch 22 Loss 0.3051\n",
      "Time taken for 1 epoch 4.180572271347046 sec\n",
      "\n",
      "Epoch 23 Batch 0 Loss 0.0168\n",
      "Epoch 23 Batch 10 Loss 0.5145\n",
      "Epoch 23 Batch 20 Loss 0.0331\n",
      "Epoch 23 Loss 0.2965\n",
      "Time taken for 1 epoch 3.8149189949035645 sec\n",
      "\n",
      "Epoch 24 Batch 0 Loss 0.0163\n",
      "Epoch 24 Batch 10 Loss 0.5020\n",
      "Epoch 24 Batch 20 Loss 0.0321\n",
      "Epoch 24 Loss 0.2891\n",
      "Time taken for 1 epoch 3.496680498123169 sec\n",
      "\n",
      "Epoch 25 Batch 0 Loss 0.0156\n",
      "Epoch 25 Batch 10 Loss 0.4884\n",
      "Epoch 25 Batch 20 Loss 0.0312\n",
      "Epoch 25 Loss 0.2822\n",
      "Time taken for 1 epoch 3.293619394302368 sec\n",
      "\n",
      "Epoch 26 Batch 0 Loss 0.0149\n",
      "Epoch 26 Batch 10 Loss 0.4742\n",
      "Epoch 26 Batch 20 Loss 0.0302\n",
      "Epoch 26 Loss 0.2753\n",
      "Time taken for 1 epoch 3.949349880218506 sec\n",
      "\n",
      "Epoch 27 Batch 0 Loss 0.0142\n",
      "Epoch 27 Batch 10 Loss 0.4594\n",
      "Epoch 27 Batch 20 Loss 0.0292\n",
      "Epoch 27 Loss 0.2683\n",
      "Time taken for 1 epoch 3.9680800437927246 sec\n",
      "\n",
      "Epoch 28 Batch 0 Loss 0.0134\n",
      "Epoch 28 Batch 10 Loss 0.4444\n",
      "Epoch 28 Batch 20 Loss 0.0282\n",
      "Epoch 28 Loss 0.2614\n",
      "Time taken for 1 epoch 3.187431812286377 sec\n",
      "\n",
      "Epoch 29 Batch 0 Loss 0.0127\n",
      "Epoch 29 Batch 10 Loss 0.4294\n",
      "Epoch 29 Batch 20 Loss 0.0273\n",
      "Epoch 29 Loss 0.2545\n",
      "Time taken for 1 epoch 3.1910438537597656 sec\n",
      "\n",
      "Epoch 30 Batch 0 Loss 0.0120\n",
      "Epoch 30 Batch 10 Loss 0.4148\n",
      "Epoch 30 Batch 20 Loss 0.0263\n",
      "Epoch 30 Loss 0.2478\n",
      "Time taken for 1 epoch 3.1119065284729004 sec\n",
      "\n",
      "Epoch 31 Batch 0 Loss 0.0114\n",
      "Epoch 31 Batch 10 Loss 0.4010\n",
      "Epoch 31 Batch 20 Loss 0.0254\n",
      "Epoch 31 Loss 0.2414\n",
      "Time taken for 1 epoch 3.6179919242858887 sec\n",
      "\n",
      "Epoch 32 Batch 0 Loss 0.0108\n",
      "Epoch 32 Batch 10 Loss 0.3880\n",
      "Epoch 32 Batch 20 Loss 0.0246\n",
      "Epoch 32 Loss 0.2356\n",
      "Time taken for 1 epoch 3.53166127204895 sec\n",
      "\n",
      "Epoch 33 Batch 0 Loss 0.0103\n",
      "Epoch 33 Batch 10 Loss 0.3761\n",
      "Epoch 33 Batch 20 Loss 0.0237\n",
      "Epoch 33 Loss 0.2302\n",
      "Time taken for 1 epoch 3.1386306285858154 sec\n",
      "\n",
      "Epoch 34 Batch 0 Loss 0.0098\n",
      "Epoch 34 Batch 10 Loss 0.3651\n",
      "Epoch 34 Batch 20 Loss 0.0229\n",
      "Epoch 34 Loss 0.2252\n",
      "Time taken for 1 epoch 3.166853189468384 sec\n",
      "\n",
      "Epoch 35 Batch 0 Loss 0.0094\n",
      "Epoch 35 Batch 10 Loss 0.3550\n",
      "Epoch 35 Batch 20 Loss 0.0221\n",
      "Epoch 35 Loss 0.2206\n",
      "Time taken for 1 epoch 3.0806965827941895 sec\n",
      "\n",
      "Epoch 36 Batch 0 Loss 0.0090\n",
      "Epoch 36 Batch 10 Loss 0.3456\n",
      "Epoch 36 Batch 20 Loss 0.0214\n",
      "Epoch 36 Loss 0.2163\n",
      "Time taken for 1 epoch 4.5746049880981445 sec\n",
      "\n",
      "Epoch 37 Batch 0 Loss 0.0087\n",
      "Epoch 37 Batch 10 Loss 0.3367\n",
      "Epoch 37 Batch 20 Loss 0.0207\n",
      "Epoch 37 Loss 0.2122\n",
      "Time taken for 1 epoch 3.1242783069610596 sec\n",
      "\n",
      "Epoch 38 Batch 0 Loss 0.0084\n",
      "Epoch 38 Batch 10 Loss 0.3284\n",
      "Epoch 38 Batch 20 Loss 0.0199\n",
      "Epoch 38 Loss 0.2083\n",
      "Time taken for 1 epoch 3.1434147357940674 sec\n",
      "\n",
      "Epoch 39 Batch 0 Loss 0.0081\n",
      "Epoch 39 Batch 10 Loss 0.3204\n",
      "Epoch 39 Batch 20 Loss 0.0193\n",
      "Epoch 39 Loss 0.2045\n",
      "Time taken for 1 epoch 3.687746286392212 sec\n",
      "\n",
      "Epoch 40 Batch 0 Loss 0.0078\n",
      "Epoch 40 Batch 10 Loss 0.3128\n",
      "Epoch 40 Batch 20 Loss 0.0186\n",
      "Epoch 40 Loss 0.2009\n",
      "Time taken for 1 epoch 3.429464817047119 sec\n",
      "\n",
      "Epoch 41 Batch 0 Loss 0.0076\n",
      "Epoch 41 Batch 10 Loss 0.3056\n",
      "Epoch 41 Batch 20 Loss 0.0179\n",
      "Epoch 41 Loss 0.1974\n",
      "Time taken for 1 epoch 3.8806846141815186 sec\n",
      "\n",
      "Epoch 42 Batch 0 Loss 0.0074\n",
      "Epoch 42 Batch 10 Loss 0.2986\n",
      "Epoch 42 Batch 20 Loss 0.0173\n",
      "Epoch 42 Loss 0.1941\n",
      "Time taken for 1 epoch 3.0509872436523438 sec\n",
      "\n",
      "Epoch 43 Batch 0 Loss 0.0072\n",
      "Epoch 43 Batch 10 Loss 0.2919\n",
      "Epoch 43 Batch 20 Loss 0.0167\n",
      "Epoch 43 Loss 0.1908\n",
      "Time taken for 1 epoch 3.0992655754089355 sec\n",
      "\n",
      "Epoch 44 Batch 0 Loss 0.0070\n",
      "Epoch 44 Batch 10 Loss 0.2854\n",
      "Epoch 44 Batch 20 Loss 0.0161\n",
      "Epoch 44 Loss 0.1877\n",
      "Time taken for 1 epoch 3.1975393295288086 sec\n",
      "\n",
      "Epoch 45 Batch 0 Loss 0.0069\n",
      "Epoch 45 Batch 10 Loss 0.2792\n",
      "Epoch 45 Batch 20 Loss 0.0155\n",
      "Epoch 45 Loss 0.1847\n",
      "Time taken for 1 epoch 3.639812707901001 sec\n",
      "\n",
      "Epoch 46 Batch 0 Loss 0.0067\n",
      "Epoch 46 Batch 10 Loss 0.2732\n",
      "Epoch 46 Batch 20 Loss 0.0149\n",
      "Epoch 46 Loss 0.1817\n",
      "Time taken for 1 epoch 3.691988468170166 sec\n",
      "\n",
      "Epoch 47 Batch 0 Loss 0.0065\n",
      "Epoch 47 Batch 10 Loss 0.2673\n",
      "Epoch 47 Batch 20 Loss 0.0144\n",
      "Epoch 47 Loss 0.1788\n",
      "Time taken for 1 epoch 3.085059404373169 sec\n",
      "\n",
      "Epoch 48 Batch 0 Loss 0.0063\n",
      "Epoch 48 Batch 10 Loss 0.2617\n",
      "Epoch 48 Batch 20 Loss 0.0138\n",
      "Epoch 48 Loss 0.1760\n",
      "Time taken for 1 epoch 3.3111279010772705 sec\n",
      "\n",
      "Epoch 49 Batch 0 Loss 0.0061\n",
      "Epoch 49 Batch 10 Loss 0.2562\n",
      "Epoch 49 Batch 20 Loss 0.0133\n",
      "Epoch 49 Loss 0.1733\n",
      "Time taken for 1 epoch 3.199850559234619 sec\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 Batch 0 Loss 0.0060\n",
      "Epoch 50 Batch 10 Loss 0.2509\n",
      "Epoch 50 Batch 20 Loss 0.0128\n",
      "Epoch 50 Loss 0.1707\n",
      "Time taken for 1 epoch 3.852137327194214 sec\n",
      "\n",
      "Epoch 51 Batch 0 Loss 0.0058\n",
      "Epoch 51 Batch 10 Loss 0.2458\n",
      "Epoch 51 Batch 20 Loss 0.0124\n",
      "Epoch 51 Loss 0.1681\n",
      "Time taken for 1 epoch 3.322279453277588 sec\n",
      "\n",
      "Epoch 52 Batch 0 Loss 0.0057\n",
      "Epoch 52 Batch 10 Loss 0.2408\n",
      "Epoch 52 Batch 20 Loss 0.0119\n",
      "Epoch 52 Loss 0.1656\n",
      "Time taken for 1 epoch 3.0980141162872314 sec\n",
      "\n",
      "Epoch 53 Batch 0 Loss 0.0055\n",
      "Epoch 53 Batch 10 Loss 0.2360\n",
      "Epoch 53 Batch 20 Loss 0.0114\n",
      "Epoch 53 Loss 0.1631\n",
      "Time taken for 1 epoch 3.231201171875 sec\n",
      "\n",
      "Epoch 54 Batch 0 Loss 0.0054\n",
      "Epoch 54 Batch 10 Loss 0.2313\n",
      "Epoch 54 Batch 20 Loss 0.0110\n",
      "Epoch 54 Loss 0.1607\n",
      "Time taken for 1 epoch 3.0648083686828613 sec\n",
      "\n",
      "Epoch 55 Batch 0 Loss 0.0053\n",
      "Epoch 55 Batch 10 Loss 0.2267\n",
      "Epoch 55 Batch 20 Loss 0.0106\n",
      "Epoch 55 Loss 0.1584\n",
      "Time taken for 1 epoch 3.910508394241333 sec\n",
      "\n",
      "Epoch 56 Batch 0 Loss 0.0052\n",
      "Epoch 56 Batch 10 Loss 0.2223\n",
      "Epoch 56 Batch 20 Loss 0.0102\n",
      "Epoch 56 Loss 0.1561\n",
      "Time taken for 1 epoch 3.225468158721924 sec\n",
      "\n",
      "Epoch 57 Batch 0 Loss 0.0051\n",
      "Epoch 57 Batch 10 Loss 0.2179\n",
      "Epoch 57 Batch 20 Loss 0.0098\n",
      "Epoch 57 Loss 0.1539\n",
      "Time taken for 1 epoch 3.0728421211242676 sec\n",
      "\n",
      "Epoch 58 Batch 0 Loss 0.0050\n",
      "Epoch 58 Batch 10 Loss 0.2137\n",
      "Epoch 58 Batch 20 Loss 0.0094\n",
      "Epoch 58 Loss 0.1518\n",
      "Time taken for 1 epoch 3.225313186645508 sec\n",
      "\n",
      "Epoch 59 Batch 0 Loss 0.0049\n",
      "Epoch 59 Batch 10 Loss 0.2096\n",
      "Epoch 59 Batch 20 Loss 0.0090\n",
      "Epoch 59 Loss 0.1496\n",
      "Time taken for 1 epoch 4.001057147979736 sec\n",
      "\n",
      "Epoch 60 Batch 0 Loss 0.0048\n",
      "Epoch 60 Batch 10 Loss 0.2057\n",
      "Epoch 60 Batch 20 Loss 0.0087\n",
      "Epoch 60 Loss 0.1476\n",
      "Time taken for 1 epoch 3.6428496837615967 sec\n",
      "\n",
      "Epoch 61 Batch 0 Loss 0.0046\n",
      "Epoch 61 Batch 10 Loss 0.2018\n",
      "Epoch 61 Batch 20 Loss 0.0083\n",
      "Epoch 61 Loss 0.1455\n",
      "Time taken for 1 epoch 3.4405124187469482 sec\n",
      "\n",
      "Epoch 62 Batch 0 Loss 0.0045\n",
      "Epoch 62 Batch 10 Loss 0.1980\n",
      "Epoch 62 Batch 20 Loss 0.0080\n",
      "Epoch 62 Loss 0.1436\n",
      "Time taken for 1 epoch 3.321377754211426 sec\n",
      "\n",
      "Epoch 63 Batch 0 Loss 0.0044\n",
      "Epoch 63 Batch 10 Loss 0.1943\n",
      "Epoch 63 Batch 20 Loss 0.0077\n",
      "Epoch 63 Loss 0.1416\n",
      "Time taken for 1 epoch 3.309629440307617 sec\n",
      "\n",
      "Epoch 64 Batch 0 Loss 0.0043\n",
      "Epoch 64 Batch 10 Loss 0.1907\n",
      "Epoch 64 Batch 20 Loss 0.0073\n",
      "Epoch 64 Loss 0.1397\n",
      "Time taken for 1 epoch 3.8448233604431152 sec\n",
      "\n",
      "Epoch 65 Batch 0 Loss 0.0042\n",
      "Epoch 65 Batch 10 Loss 0.1872\n",
      "Epoch 65 Batch 20 Loss 0.0071\n",
      "Epoch 65 Loss 0.1378\n",
      "Time taken for 1 epoch 3.3107612133026123 sec\n",
      "\n",
      "Epoch 66 Batch 0 Loss 0.0041\n",
      "Epoch 66 Batch 10 Loss 0.1838\n",
      "Epoch 66 Batch 20 Loss 0.0068\n",
      "Epoch 66 Loss 0.1360\n",
      "Time taken for 1 epoch 3.122608184814453 sec\n",
      "\n",
      "Epoch 67 Batch 0 Loss 0.0039\n",
      "Epoch 67 Batch 10 Loss 0.1804\n",
      "Epoch 67 Batch 20 Loss 0.0065\n",
      "Epoch 67 Loss 0.1342\n",
      "Time taken for 1 epoch 3.0780932903289795 sec\n",
      "\n",
      "Epoch 68 Batch 0 Loss 0.0038\n",
      "Epoch 68 Batch 10 Loss 0.1771\n",
      "Epoch 68 Batch 20 Loss 0.0062\n",
      "Epoch 68 Loss 0.1325\n",
      "Time taken for 1 epoch 3.2265844345092773 sec\n",
      "\n",
      "Epoch 69 Batch 0 Loss 0.0037\n",
      "Epoch 69 Batch 10 Loss 0.1739\n",
      "Epoch 69 Batch 20 Loss 0.0060\n",
      "Epoch 69 Loss 0.1308\n",
      "Time taken for 1 epoch 4.018968105316162 sec\n",
      "\n",
      "Epoch 70 Batch 0 Loss 0.0036\n",
      "Epoch 70 Batch 10 Loss 0.1708\n",
      "Epoch 70 Batch 20 Loss 0.0058\n",
      "Epoch 70 Loss 0.1291\n",
      "Time taken for 1 epoch 3.2284064292907715 sec\n",
      "\n",
      "Epoch 71 Batch 0 Loss 0.0035\n",
      "Epoch 71 Batch 10 Loss 0.1677\n",
      "Epoch 71 Batch 20 Loss 0.0055\n",
      "Epoch 71 Loss 0.1274\n",
      "Time taken for 1 epoch 3.242279052734375 sec\n",
      "\n",
      "Epoch 72 Batch 0 Loss 0.0034\n",
      "Epoch 72 Batch 10 Loss 0.1647\n",
      "Epoch 72 Batch 20 Loss 0.0053\n",
      "Epoch 72 Loss 0.1258\n",
      "Time taken for 1 epoch 3.130120038986206 sec\n",
      "\n",
      "Epoch 73 Batch 0 Loss 0.0033\n",
      "Epoch 73 Batch 10 Loss 0.1618\n",
      "Epoch 73 Batch 20 Loss 0.0052\n",
      "Epoch 73 Loss 0.1242\n",
      "Time taken for 1 epoch 3.539405107498169 sec\n",
      "\n",
      "Epoch 74 Batch 0 Loss 0.0032\n",
      "Epoch 74 Batch 10 Loss 0.1589\n",
      "Epoch 74 Batch 20 Loss 0.0050\n",
      "Epoch 74 Loss 0.1227\n",
      "Time taken for 1 epoch 3.743274211883545 sec\n",
      "\n",
      "Epoch 75 Batch 0 Loss 0.0031\n",
      "Epoch 75 Batch 10 Loss 0.1561\n",
      "Epoch 75 Batch 20 Loss 0.0049\n",
      "Epoch 75 Loss 0.1211\n",
      "Time taken for 1 epoch 3.2706797122955322 sec\n",
      "\n",
      "Epoch 76 Batch 0 Loss 0.0030\n",
      "Epoch 76 Batch 10 Loss 0.1533\n",
      "Epoch 76 Batch 20 Loss 0.0047\n",
      "Epoch 76 Loss 0.1196\n",
      "Time taken for 1 epoch 3.0890953540802 sec\n",
      "\n",
      "Epoch 77 Batch 0 Loss 0.0029\n",
      "Epoch 77 Batch 10 Loss 0.1507\n",
      "Epoch 77 Batch 20 Loss 0.0046\n",
      "Epoch 77 Loss 0.1182\n",
      "Time taken for 1 epoch 3.175705671310425 sec\n",
      "\n",
      "Epoch 78 Batch 0 Loss 0.0028\n",
      "Epoch 78 Batch 10 Loss 0.1480\n",
      "Epoch 78 Batch 20 Loss 0.0045\n",
      "Epoch 78 Loss 0.1167\n",
      "Time taken for 1 epoch 3.3487565517425537 sec\n",
      "\n",
      "Epoch 79 Batch 0 Loss 0.0027\n",
      "Epoch 79 Batch 10 Loss 0.1454\n",
      "Epoch 79 Batch 20 Loss 0.0043\n",
      "Epoch 79 Loss 0.1153\n",
      "Time taken for 1 epoch 3.808239221572876 sec\n",
      "\n",
      "Epoch 80 Batch 0 Loss 0.0026\n",
      "Epoch 80 Batch 10 Loss 0.1429\n",
      "Epoch 80 Batch 20 Loss 0.0042\n",
      "Epoch 80 Loss 0.1139\n",
      "Time taken for 1 epoch 3.3226358890533447 sec\n",
      "\n",
      "Epoch 81 Batch 0 Loss 0.0025\n",
      "Epoch 81 Batch 10 Loss 0.1404\n",
      "Epoch 81 Batch 20 Loss 0.0041\n",
      "Epoch 81 Loss 0.1125\n",
      "Time taken for 1 epoch 3.07879900932312 sec\n",
      "\n",
      "Epoch 82 Batch 0 Loss 0.0024\n",
      "Epoch 82 Batch 10 Loss 0.1380\n",
      "Epoch 82 Batch 20 Loss 0.0040\n",
      "Epoch 82 Loss 0.1112\n",
      "Time taken for 1 epoch 3.3537063598632812 sec\n",
      "\n",
      "Epoch 83 Batch 0 Loss 0.0023\n",
      "Epoch 83 Batch 10 Loss 0.1356\n",
      "Epoch 83 Batch 20 Loss 0.0039\n",
      "Epoch 83 Loss 0.1098\n",
      "Time taken for 1 epoch 3.726478338241577 sec\n",
      "\n",
      "Epoch 84 Batch 0 Loss 0.0023\n",
      "Epoch 84 Batch 10 Loss 0.1332\n",
      "Epoch 84 Batch 20 Loss 0.0039\n",
      "Epoch 84 Loss 0.1085\n",
      "Time taken for 1 epoch 3.207057476043701 sec\n",
      "\n",
      "Epoch 85 Batch 0 Loss 0.0022\n",
      "Epoch 85 Batch 10 Loss 0.1309\n",
      "Epoch 85 Batch 20 Loss 0.0038\n",
      "Epoch 85 Loss 0.1073\n",
      "Time taken for 1 epoch 3.1933393478393555 sec\n",
      "\n",
      "Epoch 86 Batch 0 Loss 0.0021\n",
      "Epoch 86 Batch 10 Loss 0.1287\n",
      "Epoch 86 Batch 20 Loss 0.0037\n",
      "Epoch 86 Loss 0.1060\n",
      "Time taken for 1 epoch 3.0984182357788086 sec\n",
      "\n",
      "Epoch 87 Batch 0 Loss 0.0020\n",
      "Epoch 87 Batch 10 Loss 0.1265\n",
      "Epoch 87 Batch 20 Loss 0.0036\n",
      "Epoch 87 Loss 0.1048\n",
      "Time taken for 1 epoch 3.2741973400115967 sec\n",
      "\n",
      "Epoch 88 Batch 0 Loss 0.0019\n",
      "Epoch 88 Batch 10 Loss 0.1243\n",
      "Epoch 88 Batch 20 Loss 0.0035\n",
      "Epoch 88 Loss 0.1035\n",
      "Time taken for 1 epoch 3.835405111312866 sec\n",
      "\n",
      "Epoch 89 Batch 0 Loss 0.0019\n",
      "Epoch 89 Batch 10 Loss 0.1222\n",
      "Epoch 89 Batch 20 Loss 0.0035\n",
      "Epoch 89 Loss 0.1023\n",
      "Time taken for 1 epoch 3.1632022857666016 sec\n",
      "\n",
      "Epoch 90 Batch 0 Loss 0.0018\n",
      "Epoch 90 Batch 10 Loss 0.1201\n",
      "Epoch 90 Batch 20 Loss 0.0034\n",
      "Epoch 90 Loss 0.1012\n",
      "Time taken for 1 epoch 3.2559847831726074 sec\n",
      "\n",
      "Epoch 91 Batch 0 Loss 0.0017\n",
      "Epoch 91 Batch 10 Loss 0.1181\n",
      "Epoch 91 Batch 20 Loss 0.0034\n",
      "Epoch 91 Loss 0.1000\n",
      "Time taken for 1 epoch 3.082904815673828 sec\n",
      "\n",
      "Epoch 92 Batch 0 Loss 0.0017\n",
      "Epoch 92 Batch 10 Loss 0.1160\n",
      "Epoch 92 Batch 20 Loss 0.0033\n",
      "Epoch 92 Loss 0.0989\n",
      "Time taken for 1 epoch 3.190464735031128 sec\n",
      "\n",
      "Epoch 93 Batch 0 Loss 0.0016\n",
      "Epoch 93 Batch 10 Loss 0.1141\n",
      "Epoch 93 Batch 20 Loss 0.0033\n",
      "Epoch 93 Loss 0.0977\n",
      "Time taken for 1 epoch 3.7990896701812744 sec\n",
      "\n",
      "Epoch 94 Batch 0 Loss 0.0015\n",
      "Epoch 94 Batch 10 Loss 0.1121\n",
      "Epoch 94 Batch 20 Loss 0.0033\n",
      "Epoch 94 Loss 0.0966\n",
      "Time taken for 1 epoch 3.27936053276062 sec\n",
      "\n",
      "Epoch 95 Batch 0 Loss 0.0015\n",
      "Epoch 95 Batch 10 Loss 0.1102\n",
      "Epoch 95 Batch 20 Loss 0.0032\n",
      "Epoch 95 Loss 0.0955\n",
      "Time taken for 1 epoch 3.0450053215026855 sec\n",
      "\n",
      "Epoch 96 Batch 0 Loss 0.0014\n",
      "Epoch 96 Batch 10 Loss 0.1084\n",
      "Epoch 96 Batch 20 Loss 0.0032\n",
      "Epoch 96 Loss 0.0945\n",
      "Time taken for 1 epoch 3.0651910305023193 sec\n",
      "\n",
      "Epoch 97 Batch 0 Loss 0.0014\n",
      "Epoch 97 Batch 10 Loss 0.1065\n",
      "Epoch 97 Batch 20 Loss 0.0032\n",
      "Epoch 97 Loss 0.0934\n",
      "Time taken for 1 epoch 3.2944278717041016 sec\n",
      "\n",
      "Epoch 98 Batch 0 Loss 0.0013\n",
      "Epoch 98 Batch 10 Loss 0.1047\n",
      "Epoch 98 Batch 20 Loss 0.0032\n",
      "Epoch 98 Loss 0.0924\n",
      "Time taken for 1 epoch 3.8144497871398926 sec\n",
      "\n",
      "Epoch 99 Batch 0 Loss 0.0013\n",
      "Epoch 99 Batch 10 Loss 0.1030\n",
      "Epoch 99 Batch 20 Loss 0.0032\n",
      "Epoch 99 Loss 0.0913\n",
      "Time taken for 1 epoch 3.1711041927337646 sec\n",
      "\n",
      "Epoch 100 Batch 0 Loss 0.0012\n",
      "Epoch 100 Batch 10 Loss 0.1012\n",
      "Epoch 100 Batch 20 Loss 0.0032\n",
      "Epoch 100 Loss 0.0903\n",
      "Time taken for 1 epoch 3.0491654872894287 sec\n",
      "\n",
      "Epoch 101 Batch 0 Loss 0.0012\n",
      "Epoch 101 Batch 10 Loss 0.0995\n",
      "Epoch 101 Batch 20 Loss 0.0032\n",
      "Epoch 101 Loss 0.0893\n",
      "Time taken for 1 epoch 3.0754289627075195 sec\n",
      "\n",
      "Epoch 102 Batch 0 Loss 0.0011\n",
      "Epoch 102 Batch 10 Loss 0.0978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102 Batch 20 Loss 0.0032\n",
      "Epoch 102 Loss 0.0884\n",
      "Time taken for 1 epoch 3.450599431991577 sec\n",
      "\n",
      "Epoch 103 Batch 0 Loss 0.0011\n",
      "Epoch 103 Batch 10 Loss 0.0962\n",
      "Epoch 103 Batch 20 Loss 0.0032\n",
      "Epoch 103 Loss 0.0874\n",
      "Time taken for 1 epoch 3.640829086303711 sec\n",
      "\n",
      "Epoch 104 Batch 0 Loss 0.0010\n",
      "Epoch 104 Batch 10 Loss 0.0946\n",
      "Epoch 104 Batch 20 Loss 0.0032\n",
      "Epoch 104 Loss 0.0865\n",
      "Time taken for 1 epoch 3.1988258361816406 sec\n",
      "\n",
      "Epoch 105 Batch 0 Loss 0.0010\n",
      "Epoch 105 Batch 10 Loss 0.0930\n",
      "Epoch 105 Batch 20 Loss 0.0032\n",
      "Epoch 105 Loss 0.0855\n",
      "Time taken for 1 epoch 3.067476511001587 sec\n",
      "\n",
      "Epoch 106 Batch 0 Loss 0.0010\n",
      "Epoch 106 Batch 10 Loss 0.0914\n",
      "Epoch 106 Batch 20 Loss 0.0032\n",
      "Epoch 106 Loss 0.0846\n",
      "Time taken for 1 epoch 3.1922454833984375 sec\n",
      "\n",
      "Epoch 107 Batch 0 Loss 0.0009\n",
      "Epoch 107 Batch 10 Loss 0.0899\n",
      "Epoch 107 Batch 20 Loss 0.0032\n",
      "Epoch 107 Loss 0.0837\n",
      "Time taken for 1 epoch 3.518932819366455 sec\n",
      "\n",
      "Epoch 108 Batch 0 Loss 0.0009\n",
      "Epoch 108 Batch 10 Loss 0.0884\n",
      "Epoch 108 Batch 20 Loss 0.0032\n",
      "Epoch 108 Loss 0.0828\n",
      "Time taken for 1 epoch 3.459437370300293 sec\n",
      "\n",
      "Epoch 109 Batch 0 Loss 0.0009\n",
      "Epoch 109 Batch 10 Loss 0.0869\n",
      "Epoch 109 Batch 20 Loss 0.0032\n",
      "Epoch 109 Loss 0.0819\n",
      "Time taken for 1 epoch 3.204195499420166 sec\n",
      "\n",
      "Epoch 110 Batch 0 Loss 0.0009\n",
      "Epoch 110 Batch 10 Loss 0.0854\n",
      "Epoch 110 Batch 20 Loss 0.0033\n",
      "Epoch 110 Loss 0.0810\n",
      "Time taken for 1 epoch 3.1030004024505615 sec\n",
      "\n",
      "Epoch 111 Batch 0 Loss 0.0008\n",
      "Epoch 111 Batch 10 Loss 0.0840\n",
      "Epoch 111 Batch 20 Loss 0.0033\n",
      "Epoch 111 Loss 0.0802\n",
      "Time taken for 1 epoch 3.295865058898926 sec\n",
      "\n",
      "Epoch 112 Batch 0 Loss 0.0008\n",
      "Epoch 112 Batch 10 Loss 0.0826\n",
      "Epoch 112 Batch 20 Loss 0.0033\n",
      "Epoch 112 Loss 0.0794\n",
      "Time taken for 1 epoch 3.5577893257141113 sec\n",
      "\n",
      "Epoch 113 Batch 0 Loss 0.0008\n",
      "Epoch 113 Batch 10 Loss 0.0812\n",
      "Epoch 113 Batch 20 Loss 0.0033\n",
      "Epoch 113 Loss 0.0785\n",
      "Time taken for 1 epoch 3.4318509101867676 sec\n",
      "\n",
      "Epoch 114 Batch 0 Loss 0.0008\n",
      "Epoch 114 Batch 10 Loss 0.0799\n",
      "Epoch 114 Batch 20 Loss 0.0033\n",
      "Epoch 114 Loss 0.0777\n",
      "Time taken for 1 epoch 3.1172828674316406 sec\n",
      "\n",
      "Epoch 115 Batch 0 Loss 0.0007\n",
      "Epoch 115 Batch 10 Loss 0.0785\n",
      "Epoch 115 Batch 20 Loss 0.0034\n",
      "Epoch 115 Loss 0.0769\n",
      "Time taken for 1 epoch 3.11265230178833 sec\n",
      "\n",
      "Epoch 116 Batch 0 Loss 0.0007\n",
      "Epoch 116 Batch 10 Loss 0.0772\n",
      "Epoch 116 Batch 20 Loss 0.0034\n",
      "Epoch 116 Loss 0.0761\n",
      "Time taken for 1 epoch 3.1657049655914307 sec\n",
      "\n",
      "Epoch 117 Batch 0 Loss 0.0007\n",
      "Epoch 117 Batch 10 Loss 0.0759\n",
      "Epoch 117 Batch 20 Loss 0.0034\n",
      "Epoch 117 Loss 0.0753\n",
      "Time taken for 1 epoch 3.724853992462158 sec\n",
      "\n",
      "Epoch 118 Batch 0 Loss 0.0007\n",
      "Epoch 118 Batch 10 Loss 0.0747\n",
      "Epoch 118 Batch 20 Loss 0.0034\n",
      "Epoch 118 Loss 0.0745\n",
      "Time taken for 1 epoch 3.393653631210327 sec\n",
      "\n",
      "Epoch 119 Batch 0 Loss 0.0007\n",
      "Epoch 119 Batch 10 Loss 0.0734\n",
      "Epoch 119 Batch 20 Loss 0.0035\n",
      "Epoch 119 Loss 0.0738\n",
      "Time taken for 1 epoch 3.0555660724639893 sec\n",
      "\n",
      "Epoch 120 Batch 0 Loss 0.0006\n",
      "Epoch 120 Batch 10 Loss 0.0722\n",
      "Epoch 120 Batch 20 Loss 0.0035\n",
      "Epoch 120 Loss 0.0730\n",
      "Time taken for 1 epoch 3.0766801834106445 sec\n",
      "\n",
      "Epoch 121 Batch 0 Loss 0.0006\n",
      "Epoch 121 Batch 10 Loss 0.0710\n",
      "Epoch 121 Batch 20 Loss 0.0035\n",
      "Epoch 121 Loss 0.0723\n",
      "Time taken for 1 epoch 3.182133197784424 sec\n",
      "\n",
      "Epoch 122 Batch 0 Loss 0.0006\n",
      "Epoch 122 Batch 10 Loss 0.0698\n",
      "Epoch 122 Batch 20 Loss 0.0035\n",
      "Epoch 122 Loss 0.0715\n",
      "Time taken for 1 epoch 3.8526580333709717 sec\n",
      "\n",
      "Epoch 123 Batch 0 Loss 0.0006\n",
      "Epoch 123 Batch 10 Loss 0.0686\n",
      "Epoch 123 Batch 20 Loss 0.0036\n",
      "Epoch 123 Loss 0.0708\n",
      "Time taken for 1 epoch 3.4029271602630615 sec\n",
      "\n",
      "Epoch 124 Batch 0 Loss 0.0006\n",
      "Epoch 124 Batch 10 Loss 0.0675\n",
      "Epoch 124 Batch 20 Loss 0.0036\n",
      "Epoch 124 Loss 0.0701\n",
      "Time taken for 1 epoch 3.100080966949463 sec\n",
      "\n",
      "Epoch 125 Batch 0 Loss 0.0006\n",
      "Epoch 125 Batch 10 Loss 0.0663\n",
      "Epoch 125 Batch 20 Loss 0.0036\n",
      "Epoch 125 Loss 0.0694\n",
      "Time taken for 1 epoch 3.0680291652679443 sec\n",
      "\n",
      "Epoch 126 Batch 0 Loss 0.0006\n",
      "Epoch 126 Batch 10 Loss 0.0652\n",
      "Epoch 126 Batch 20 Loss 0.0036\n",
      "Epoch 126 Loss 0.0687\n",
      "Time taken for 1 epoch 3.4568896293640137 sec\n",
      "\n",
      "Epoch 127 Batch 0 Loss 0.0005\n",
      "Epoch 127 Batch 10 Loss 0.0641\n",
      "Epoch 127 Batch 20 Loss 0.0036\n",
      "Epoch 127 Loss 0.0680\n",
      "Time taken for 1 epoch 3.748185873031616 sec\n",
      "\n",
      "Epoch 128 Batch 0 Loss 0.0005\n",
      "Epoch 128 Batch 10 Loss 0.0630\n",
      "Epoch 128 Batch 20 Loss 0.0036\n",
      "Epoch 128 Loss 0.0673\n",
      "Time taken for 1 epoch 3.1498281955718994 sec\n",
      "\n",
      "Epoch 129 Batch 0 Loss 0.0005\n",
      "Epoch 129 Batch 10 Loss 0.0620\n",
      "Epoch 129 Batch 20 Loss 0.0036\n",
      "Epoch 129 Loss 0.0667\n",
      "Time taken for 1 epoch 3.088179588317871 sec\n",
      "\n",
      "Epoch 130 Batch 0 Loss 0.0005\n",
      "Epoch 130 Batch 10 Loss 0.0609\n",
      "Epoch 130 Batch 20 Loss 0.0036\n",
      "Epoch 130 Loss 0.0660\n",
      "Time taken for 1 epoch 3.211395263671875 sec\n",
      "\n",
      "Epoch 131 Batch 0 Loss 0.0005\n",
      "Epoch 131 Batch 10 Loss 0.0599\n",
      "Epoch 131 Batch 20 Loss 0.0036\n",
      "Epoch 131 Loss 0.0654\n",
      "Time taken for 1 epoch 3.521745204925537 sec\n",
      "\n",
      "Epoch 132 Batch 0 Loss 0.0005\n",
      "Epoch 132 Batch 10 Loss 0.0589\n",
      "Epoch 132 Batch 20 Loss 0.0036\n",
      "Epoch 132 Loss 0.0647\n",
      "Time taken for 1 epoch 4.170658588409424 sec\n",
      "\n",
      "Epoch 133 Batch 0 Loss 0.0005\n",
      "Epoch 133 Batch 10 Loss 0.0579\n",
      "Epoch 133 Batch 20 Loss 0.0036\n",
      "Epoch 133 Loss 0.0641\n",
      "Time taken for 1 epoch 3.475261926651001 sec\n",
      "\n",
      "Epoch 134 Batch 0 Loss 0.0005\n",
      "Epoch 134 Batch 10 Loss 0.0569\n",
      "Epoch 134 Batch 20 Loss 0.0036\n",
      "Epoch 134 Loss 0.0635\n",
      "Time taken for 1 epoch 3.4323415756225586 sec\n",
      "\n",
      "Epoch 135 Batch 0 Loss 0.0005\n",
      "Epoch 135 Batch 10 Loss 0.0560\n",
      "Epoch 135 Batch 20 Loss 0.0036\n",
      "Epoch 135 Loss 0.0629\n",
      "Time taken for 1 epoch 3.2955896854400635 sec\n",
      "\n",
      "Epoch 136 Batch 0 Loss 0.0005\n",
      "Epoch 136 Batch 10 Loss 0.0550\n",
      "Epoch 136 Batch 20 Loss 0.0036\n",
      "Epoch 136 Loss 0.0622\n",
      "Time taken for 1 epoch 3.738225221633911 sec\n",
      "\n",
      "Epoch 137 Batch 0 Loss 0.0005\n",
      "Epoch 137 Batch 10 Loss 0.0541\n",
      "Epoch 137 Batch 20 Loss 0.0035\n",
      "Epoch 137 Loss 0.0616\n",
      "Time taken for 1 epoch 3.160508632659912 sec\n",
      "\n",
      "Epoch 138 Batch 0 Loss 0.0004\n",
      "Epoch 138 Batch 10 Loss 0.0531\n",
      "Epoch 138 Batch 20 Loss 0.0035\n",
      "Epoch 138 Loss 0.0610\n",
      "Time taken for 1 epoch 3.2503085136413574 sec\n",
      "\n",
      "Epoch 139 Batch 0 Loss 0.0004\n",
      "Epoch 139 Batch 10 Loss 0.0522\n",
      "Epoch 139 Batch 20 Loss 0.0035\n",
      "Epoch 139 Loss 0.0605\n",
      "Time taken for 1 epoch 3.0725510120391846 sec\n",
      "\n",
      "Epoch 140 Batch 0 Loss 0.0004\n",
      "Epoch 140 Batch 10 Loss 0.0513\n",
      "Epoch 140 Batch 20 Loss 0.0035\n",
      "Epoch 140 Loss 0.0599\n",
      "Time taken for 1 epoch 3.194722890853882 sec\n",
      "\n",
      "Epoch 141 Batch 0 Loss 0.0004\n",
      "Epoch 141 Batch 10 Loss 0.0505\n",
      "Epoch 141 Batch 20 Loss 0.0034\n",
      "Epoch 141 Loss 0.0593\n",
      "Time taken for 1 epoch 4.020251035690308 sec\n",
      "\n",
      "Epoch 142 Batch 0 Loss 0.0004\n",
      "Epoch 142 Batch 10 Loss 0.0496\n",
      "Epoch 142 Batch 20 Loss 0.0034\n",
      "Epoch 142 Loss 0.0587\n",
      "Time taken for 1 epoch 3.1991844177246094 sec\n",
      "\n",
      "Epoch 143 Batch 0 Loss 0.0004\n",
      "Epoch 143 Batch 10 Loss 0.0487\n",
      "Epoch 143 Batch 20 Loss 0.0034\n",
      "Epoch 143 Loss 0.0582\n",
      "Time taken for 1 epoch 3.0633432865142822 sec\n",
      "\n",
      "Epoch 144 Batch 0 Loss 0.0004\n",
      "Epoch 144 Batch 10 Loss 0.0479\n",
      "Epoch 144 Batch 20 Loss 0.0033\n",
      "Epoch 144 Loss 0.0576\n",
      "Time taken for 1 epoch 3.0597898960113525 sec\n",
      "\n",
      "Epoch 145 Batch 0 Loss 0.0004\n",
      "Epoch 145 Batch 10 Loss 0.0471\n",
      "Epoch 145 Batch 20 Loss 0.0033\n",
      "Epoch 145 Loss 0.0571\n",
      "Time taken for 1 epoch 3.2877256870269775 sec\n",
      "\n",
      "Epoch 146 Batch 0 Loss 0.0004\n",
      "Epoch 146 Batch 10 Loss 0.0462\n",
      "Epoch 146 Batch 20 Loss 0.0033\n",
      "Epoch 146 Loss 0.0565\n",
      "Time taken for 1 epoch 3.7806360721588135 sec\n",
      "\n",
      "Epoch 147 Batch 0 Loss 0.0004\n",
      "Epoch 147 Batch 10 Loss 0.0454\n",
      "Epoch 147 Batch 20 Loss 0.0032\n",
      "Epoch 147 Loss 0.0560\n",
      "Time taken for 1 epoch 3.1798453330993652 sec\n",
      "\n",
      "Epoch 148 Batch 0 Loss 0.0004\n",
      "Epoch 148 Batch 10 Loss 0.0446\n",
      "Epoch 148 Batch 20 Loss 0.0032\n",
      "Epoch 148 Loss 0.0555\n",
      "Time taken for 1 epoch 3.0859804153442383 sec\n",
      "\n",
      "Epoch 149 Batch 0 Loss 0.0004\n",
      "Epoch 149 Batch 10 Loss 0.0438\n",
      "Epoch 149 Batch 20 Loss 0.0031\n",
      "Epoch 149 Loss 0.0549\n",
      "Time taken for 1 epoch 3.0659725666046143 sec\n",
      "\n",
      "Epoch 150 Batch 0 Loss 0.0004\n",
      "Epoch 150 Batch 10 Loss 0.0431\n",
      "Epoch 150 Batch 20 Loss 0.0031\n",
      "Epoch 150 Loss 0.0544\n",
      "Time taken for 1 epoch 3.5193657875061035 sec\n",
      "\n",
      "Epoch 151 Batch 0 Loss 0.0004\n",
      "Epoch 151 Batch 10 Loss 0.0423\n",
      "Epoch 151 Batch 20 Loss 0.0031\n",
      "Epoch 151 Loss 0.0539\n",
      "Time taken for 1 epoch 3.69313383102417 sec\n",
      "\n",
      "Epoch 152 Batch 0 Loss 0.0004\n",
      "Epoch 152 Batch 10 Loss 0.0415\n",
      "Epoch 152 Batch 20 Loss 0.0030\n",
      "Epoch 152 Loss 0.0534\n",
      "Time taken for 1 epoch 3.2090983390808105 sec\n",
      "\n",
      "Epoch 153 Batch 0 Loss 0.0004\n",
      "Epoch 153 Batch 10 Loss 0.0408\n",
      "Epoch 153 Batch 20 Loss 0.0030\n",
      "Epoch 153 Loss 0.0529\n",
      "Time taken for 1 epoch 3.1171905994415283 sec\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 154 Batch 0 Loss 0.0003\n",
      "Epoch 154 Batch 10 Loss 0.0401\n",
      "Epoch 154 Batch 20 Loss 0.0029\n",
      "Epoch 154 Loss 0.0524\n",
      "Time taken for 1 epoch 3.1320629119873047 sec\n",
      "\n",
      "Epoch 155 Batch 0 Loss 0.0003\n",
      "Epoch 155 Batch 10 Loss 0.0393\n",
      "Epoch 155 Batch 20 Loss 0.0029\n",
      "Epoch 155 Loss 0.0519\n",
      "Time taken for 1 epoch 3.6151516437530518 sec\n",
      "\n",
      "Epoch 156 Batch 0 Loss 0.0003\n",
      "Epoch 156 Batch 10 Loss 0.0386\n",
      "Epoch 156 Batch 20 Loss 0.0028\n",
      "Epoch 156 Loss 0.0515\n",
      "Time taken for 1 epoch 3.3481180667877197 sec\n",
      "\n",
      "Epoch 157 Batch 0 Loss 0.0003\n",
      "Epoch 157 Batch 10 Loss 0.0379\n",
      "Epoch 157 Batch 20 Loss 0.0028\n",
      "Epoch 157 Loss 0.0510\n",
      "Time taken for 1 epoch 3.28289532661438 sec\n",
      "\n",
      "Epoch 158 Batch 0 Loss 0.0003\n",
      "Epoch 158 Batch 10 Loss 0.0372\n",
      "Epoch 158 Batch 20 Loss 0.0028\n",
      "Epoch 158 Loss 0.0505\n",
      "Time taken for 1 epoch 3.264820098876953 sec\n",
      "\n",
      "Epoch 159 Batch 0 Loss 0.0003\n",
      "Epoch 159 Batch 10 Loss 0.0365\n",
      "Epoch 159 Batch 20 Loss 0.0027\n",
      "Epoch 159 Loss 0.0500\n",
      "Time taken for 1 epoch 3.2240118980407715 sec\n",
      "\n",
      "Epoch 160 Batch 0 Loss 0.0003\n",
      "Epoch 160 Batch 10 Loss 0.0359\n",
      "Epoch 160 Batch 20 Loss 0.0027\n",
      "Epoch 160 Loss 0.0496\n",
      "Time taken for 1 epoch 3.7916972637176514 sec\n",
      "\n",
      "Epoch 161 Batch 0 Loss 0.0003\n",
      "Epoch 161 Batch 10 Loss 0.0352\n",
      "Epoch 161 Batch 20 Loss 0.0026\n",
      "Epoch 161 Loss 0.0491\n",
      "Time taken for 1 epoch 3.34360408782959 sec\n",
      "\n",
      "Epoch 162 Batch 0 Loss 0.0003\n",
      "Epoch 162 Batch 10 Loss 0.0345\n",
      "Epoch 162 Batch 20 Loss 0.0026\n",
      "Epoch 162 Loss 0.0487\n",
      "Time taken for 1 epoch 3.1818864345550537 sec\n",
      "\n",
      "Epoch 163 Batch 0 Loss 0.0003\n",
      "Epoch 163 Batch 10 Loss 0.0339\n",
      "Epoch 163 Batch 20 Loss 0.0025\n",
      "Epoch 163 Loss 0.0482\n",
      "Time taken for 1 epoch 3.123811960220337 sec\n",
      "\n",
      "Epoch 164 Batch 0 Loss 0.0003\n",
      "Epoch 164 Batch 10 Loss 0.0332\n",
      "Epoch 164 Batch 20 Loss 0.0025\n",
      "Epoch 164 Loss 0.0478\n",
      "Time taken for 1 epoch 3.229673385620117 sec\n",
      "\n",
      "Epoch 165 Batch 0 Loss 0.0003\n",
      "Epoch 165 Batch 10 Loss 0.0326\n",
      "Epoch 165 Batch 20 Loss 0.0025\n",
      "Epoch 165 Loss 0.0473\n",
      "Time taken for 1 epoch 3.8877146244049072 sec\n",
      "\n",
      "Epoch 166 Batch 0 Loss 0.0003\n",
      "Epoch 166 Batch 10 Loss 0.0319\n",
      "Epoch 166 Batch 20 Loss 0.0024\n",
      "Epoch 166 Loss 0.0469\n",
      "Time taken for 1 epoch 3.0888748168945312 sec\n",
      "\n",
      "Epoch 167 Batch 0 Loss 0.0003\n",
      "Epoch 167 Batch 10 Loss 0.0313\n",
      "Epoch 167 Batch 20 Loss 0.0024\n",
      "Epoch 167 Loss 0.0465\n",
      "Time taken for 1 epoch 3.186387538909912 sec\n",
      "\n",
      "Epoch 168 Batch 0 Loss 0.0003\n",
      "Epoch 168 Batch 10 Loss 0.0307\n",
      "Epoch 168 Batch 20 Loss 0.0024\n",
      "Epoch 168 Loss 0.0460\n",
      "Time taken for 1 epoch 3.062596559524536 sec\n",
      "\n",
      "Epoch 169 Batch 0 Loss 0.0003\n",
      "Epoch 169 Batch 10 Loss 0.0301\n",
      "Epoch 169 Batch 20 Loss 0.0023\n",
      "Epoch 169 Loss 0.0456\n",
      "Time taken for 1 epoch 3.399975299835205 sec\n",
      "\n",
      "Epoch 170 Batch 0 Loss 0.0003\n",
      "Epoch 170 Batch 10 Loss 0.0295\n",
      "Epoch 170 Batch 20 Loss 0.0023\n",
      "Epoch 170 Loss 0.0452\n",
      "Time taken for 1 epoch 3.766589403152466 sec\n",
      "\n",
      "Epoch 171 Batch 0 Loss 0.0003\n",
      "Epoch 171 Batch 10 Loss 0.0289\n",
      "Epoch 171 Batch 20 Loss 0.0023\n",
      "Epoch 171 Loss 0.0448\n",
      "Time taken for 1 epoch 3.1800973415374756 sec\n",
      "\n",
      "Epoch 172 Batch 0 Loss 0.0003\n",
      "Epoch 172 Batch 10 Loss 0.0283\n",
      "Epoch 172 Batch 20 Loss 0.0023\n",
      "Epoch 172 Loss 0.0444\n",
      "Time taken for 1 epoch 3.0900821685791016 sec\n",
      "\n",
      "Epoch 173 Batch 0 Loss 0.0003\n",
      "Epoch 173 Batch 10 Loss 0.0278\n",
      "Epoch 173 Batch 20 Loss 0.0022\n",
      "Epoch 173 Loss 0.0440\n",
      "Time taken for 1 epoch 3.083699941635132 sec\n",
      "\n",
      "Epoch 174 Batch 0 Loss 0.0003\n",
      "Epoch 174 Batch 10 Loss 0.0272\n",
      "Epoch 174 Batch 20 Loss 0.0022\n",
      "Epoch 174 Loss 0.0436\n",
      "Time taken for 1 epoch 3.4151289463043213 sec\n",
      "\n",
      "Epoch 175 Batch 0 Loss 0.0003\n",
      "Epoch 175 Batch 10 Loss 0.0266\n",
      "Epoch 175 Batch 20 Loss 0.0022\n",
      "Epoch 175 Loss 0.0432\n",
      "Time taken for 1 epoch 3.610448122024536 sec\n",
      "\n",
      "Epoch 176 Batch 0 Loss 0.0003\n",
      "Epoch 176 Batch 10 Loss 0.0261\n",
      "Epoch 176 Batch 20 Loss 0.0021\n",
      "Epoch 176 Loss 0.0428\n",
      "Time taken for 1 epoch 3.2630321979522705 sec\n",
      "\n",
      "Epoch 177 Batch 0 Loss 0.0003\n",
      "Epoch 177 Batch 10 Loss 0.0255\n",
      "Epoch 177 Batch 20 Loss 0.0021\n",
      "Epoch 177 Loss 0.0424\n",
      "Time taken for 1 epoch 3.103088855743408 sec\n",
      "\n",
      "Epoch 178 Batch 0 Loss 0.0003\n",
      "Epoch 178 Batch 10 Loss 0.0250\n",
      "Epoch 178 Batch 20 Loss 0.0021\n",
      "Epoch 178 Loss 0.0420\n",
      "Time taken for 1 epoch 3.0745975971221924 sec\n",
      "\n",
      "Epoch 179 Batch 0 Loss 0.0003\n",
      "Epoch 179 Batch 10 Loss 0.0244\n",
      "Epoch 179 Batch 20 Loss 0.0020\n",
      "Epoch 179 Loss 0.0416\n",
      "Time taken for 1 epoch 3.4436702728271484 sec\n",
      "\n",
      "Epoch 180 Batch 0 Loss 0.0003\n",
      "Epoch 180 Batch 10 Loss 0.0239\n",
      "Epoch 180 Batch 20 Loss 0.0020\n",
      "Epoch 180 Loss 0.0413\n",
      "Time taken for 1 epoch 3.574308156967163 sec\n",
      "\n",
      "Epoch 181 Batch 0 Loss 0.0003\n",
      "Epoch 181 Batch 10 Loss 0.0234\n",
      "Epoch 181 Batch 20 Loss 0.0020\n",
      "Epoch 181 Loss 0.0409\n",
      "Time taken for 1 epoch 3.273036003112793 sec\n",
      "\n",
      "Epoch 182 Batch 0 Loss 0.0003\n",
      "Epoch 182 Batch 10 Loss 0.0229\n",
      "Epoch 182 Batch 20 Loss 0.0019\n",
      "Epoch 182 Loss 0.0405\n",
      "Time taken for 1 epoch 3.043602705001831 sec\n",
      "\n",
      "Epoch 183 Batch 0 Loss 0.0003\n",
      "Epoch 183 Batch 10 Loss 0.0224\n",
      "Epoch 183 Batch 20 Loss 0.0019\n",
      "Epoch 183 Loss 0.0402\n",
      "Time taken for 1 epoch 3.0631189346313477 sec\n",
      "\n",
      "Epoch 184 Batch 0 Loss 0.0002\n",
      "Epoch 184 Batch 10 Loss 0.0219\n",
      "Epoch 184 Batch 20 Loss 0.0019\n",
      "Epoch 184 Loss 0.0398\n",
      "Time taken for 1 epoch 3.5907163619995117 sec\n",
      "\n",
      "Epoch 185 Batch 0 Loss 0.0002\n",
      "Epoch 185 Batch 10 Loss 0.0214\n",
      "Epoch 185 Batch 20 Loss 0.0019\n",
      "Epoch 185 Loss 0.0394\n",
      "Time taken for 1 epoch 3.4520061016082764 sec\n",
      "\n",
      "Epoch 186 Batch 0 Loss 0.0002\n",
      "Epoch 186 Batch 10 Loss 0.0209\n",
      "Epoch 186 Batch 20 Loss 0.0018\n",
      "Epoch 186 Loss 0.0391\n",
      "Time taken for 1 epoch 3.1608588695526123 sec\n",
      "\n",
      "Epoch 187 Batch 0 Loss 0.0002\n",
      "Epoch 187 Batch 10 Loss 0.0204\n",
      "Epoch 187 Batch 20 Loss 0.0018\n",
      "Epoch 187 Loss 0.0387\n",
      "Time taken for 1 epoch 3.0539188385009766 sec\n",
      "\n",
      "Epoch 188 Batch 0 Loss 0.0002\n",
      "Epoch 188 Batch 10 Loss 0.0200\n",
      "Epoch 188 Batch 20 Loss 0.0018\n",
      "Epoch 188 Loss 0.0384\n",
      "Time taken for 1 epoch 3.179394483566284 sec\n",
      "\n",
      "Epoch 189 Batch 0 Loss 0.0002\n",
      "Epoch 189 Batch 10 Loss 0.0195\n",
      "Epoch 189 Batch 20 Loss 0.0017\n",
      "Epoch 189 Loss 0.0380\n",
      "Time taken for 1 epoch 3.7807812690734863 sec\n",
      "\n",
      "Epoch 190 Batch 0 Loss 0.0002\n",
      "Epoch 190 Batch 10 Loss 0.0190\n",
      "Epoch 190 Batch 20 Loss 0.0017\n",
      "Epoch 190 Loss 0.0377\n",
      "Time taken for 1 epoch 3.255265235900879 sec\n",
      "\n",
      "Epoch 191 Batch 0 Loss 0.0002\n",
      "Epoch 191 Batch 10 Loss 0.0186\n",
      "Epoch 191 Batch 20 Loss 0.0017\n",
      "Epoch 191 Loss 0.0374\n",
      "Time taken for 1 epoch 3.1589531898498535 sec\n",
      "\n",
      "Epoch 192 Batch 0 Loss 0.0002\n",
      "Epoch 192 Batch 10 Loss 0.0181\n",
      "Epoch 192 Batch 20 Loss 0.0017\n",
      "Epoch 192 Loss 0.0370\n",
      "Time taken for 1 epoch 3.0612614154815674 sec\n",
      "\n",
      "Epoch 193 Batch 0 Loss 0.0002\n",
      "Epoch 193 Batch 10 Loss 0.0177\n",
      "Epoch 193 Batch 20 Loss 0.0016\n",
      "Epoch 193 Loss 0.0367\n",
      "Time taken for 1 epoch 3.1910743713378906 sec\n",
      "\n",
      "Epoch 194 Batch 0 Loss 0.0002\n",
      "Epoch 194 Batch 10 Loss 0.0173\n",
      "Epoch 194 Batch 20 Loss 0.0016\n",
      "Epoch 194 Loss 0.0364\n",
      "Time taken for 1 epoch 3.805859327316284 sec\n",
      "\n",
      "Epoch 195 Batch 0 Loss 0.0002\n",
      "Epoch 195 Batch 10 Loss 0.0169\n",
      "Epoch 195 Batch 20 Loss 0.0016\n",
      "Epoch 195 Loss 0.0361\n",
      "Time taken for 1 epoch 3.2574522495269775 sec\n",
      "\n",
      "Epoch 196 Batch 0 Loss 0.0002\n",
      "Epoch 196 Batch 10 Loss 0.0164\n",
      "Epoch 196 Batch 20 Loss 0.0016\n",
      "Epoch 196 Loss 0.0357\n",
      "Time taken for 1 epoch 3.0620834827423096 sec\n",
      "\n",
      "Epoch 197 Batch 0 Loss 0.0002\n",
      "Epoch 197 Batch 10 Loss 0.0160\n",
      "Epoch 197 Batch 20 Loss 0.0015\n",
      "Epoch 197 Loss 0.0354\n",
      "Time taken for 1 epoch 3.071099281311035 sec\n",
      "\n",
      "Epoch 198 Batch 0 Loss 0.0002\n",
      "Epoch 198 Batch 10 Loss 0.0156\n",
      "Epoch 198 Batch 20 Loss 0.0015\n",
      "Epoch 198 Loss 0.0351\n",
      "Time taken for 1 epoch 3.2917308807373047 sec\n",
      "\n",
      "Epoch 199 Batch 0 Loss 0.0002\n",
      "Epoch 199 Batch 10 Loss 0.0152\n",
      "Epoch 199 Batch 20 Loss 0.0015\n",
      "Epoch 199 Loss 0.0348\n",
      "Time taken for 1 epoch 3.773719072341919 sec\n",
      "\n",
      "Epoch 200 Batch 0 Loss 0.0002\n",
      "Epoch 200 Batch 10 Loss 0.0148\n",
      "Epoch 200 Batch 20 Loss 0.0015\n",
      "Epoch 200 Loss 0.0345\n",
      "Time taken for 1 epoch 3.2177088260650635 sec\n",
      "\n",
      "Epoch 201 Batch 0 Loss 0.0002\n",
      "Epoch 201 Batch 10 Loss 0.0145\n",
      "Epoch 201 Batch 20 Loss 0.0015\n",
      "Epoch 201 Loss 0.0342\n",
      "Time taken for 1 epoch 3.1219661235809326 sec\n",
      "\n",
      "Epoch 202 Batch 0 Loss 0.0002\n",
      "Epoch 202 Batch 10 Loss 0.0141\n",
      "Epoch 202 Batch 20 Loss 0.0015\n",
      "Epoch 202 Loss 0.0339\n",
      "Time taken for 1 epoch 3.1144258975982666 sec\n",
      "\n",
      "Epoch 203 Batch 0 Loss 0.0002\n",
      "Epoch 203 Batch 10 Loss 0.0137\n",
      "Epoch 203 Batch 20 Loss 0.0015\n",
      "Epoch 203 Loss 0.0336\n",
      "Time taken for 1 epoch 3.242940664291382 sec\n",
      "\n",
      "Epoch 204 Batch 0 Loss 0.0002\n",
      "Epoch 204 Batch 10 Loss 0.0134\n",
      "Epoch 204 Batch 20 Loss 0.0014\n",
      "Epoch 204 Loss 0.0333\n",
      "Time taken for 1 epoch 3.7399959564208984 sec\n",
      "\n",
      "Epoch 205 Batch 0 Loss 0.0002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 205 Batch 10 Loss 0.0130\n",
      "Epoch 205 Batch 20 Loss 0.0014\n",
      "Epoch 205 Loss 0.0330\n",
      "Time taken for 1 epoch 3.2648797035217285 sec\n",
      "\n",
      "Epoch 206 Batch 0 Loss 0.0002\n",
      "Epoch 206 Batch 10 Loss 0.0127\n",
      "Epoch 206 Batch 20 Loss 0.0014\n",
      "Epoch 206 Loss 0.0327\n",
      "Time taken for 1 epoch 3.1141114234924316 sec\n",
      "\n",
      "Epoch 207 Batch 0 Loss 0.0002\n",
      "Epoch 207 Batch 10 Loss 0.0123\n",
      "Epoch 207 Batch 20 Loss 0.0014\n",
      "Epoch 207 Loss 0.0324\n",
      "Time taken for 1 epoch 3.171097993850708 sec\n",
      "\n",
      "Epoch 208 Batch 0 Loss 0.0002\n",
      "Epoch 208 Batch 10 Loss 0.0120\n",
      "Epoch 208 Batch 20 Loss 0.0014\n",
      "Epoch 208 Loss 0.0321\n",
      "Time taken for 1 epoch 3.1967530250549316 sec\n",
      "\n",
      "Epoch 209 Batch 0 Loss 0.0003\n",
      "Epoch 209 Batch 10 Loss 0.0117\n",
      "Epoch 209 Batch 20 Loss 0.0013\n",
      "Epoch 209 Loss 0.0318\n",
      "Time taken for 1 epoch 3.6953253746032715 sec\n",
      "\n",
      "Epoch 210 Batch 0 Loss 0.0002\n",
      "Epoch 210 Batch 10 Loss 0.0113\n",
      "Epoch 210 Batch 20 Loss 0.0013\n",
      "Epoch 210 Loss 0.0315\n",
      "Time taken for 1 epoch 3.2389976978302 sec\n",
      "\n",
      "Epoch 211 Batch 0 Loss 0.0002\n",
      "Epoch 211 Batch 10 Loss 0.0110\n",
      "Epoch 211 Batch 20 Loss 0.0013\n",
      "Epoch 211 Loss 0.0313\n",
      "Time taken for 1 epoch 3.0755622386932373 sec\n",
      "\n",
      "Epoch 212 Batch 0 Loss 0.0002\n",
      "Epoch 212 Batch 10 Loss 0.0107\n",
      "Epoch 212 Batch 20 Loss 0.0013\n",
      "Epoch 212 Loss 0.0310\n",
      "Time taken for 1 epoch 3.177678108215332 sec\n",
      "\n",
      "Epoch 213 Batch 0 Loss 0.0002\n",
      "Epoch 213 Batch 10 Loss 0.0104\n",
      "Epoch 213 Batch 20 Loss 0.0013\n",
      "Epoch 213 Loss 0.0307\n",
      "Time taken for 1 epoch 3.35569167137146 sec\n",
      "\n",
      "Epoch 214 Batch 0 Loss 0.0002\n",
      "Epoch 214 Batch 10 Loss 0.0101\n",
      "Epoch 214 Batch 20 Loss 0.0012\n",
      "Epoch 214 Loss 0.0304\n",
      "Time taken for 1 epoch 3.6513078212738037 sec\n",
      "\n",
      "Epoch 215 Batch 0 Loss 0.0002\n",
      "Epoch 215 Batch 10 Loss 0.0098\n",
      "Epoch 215 Batch 20 Loss 0.0012\n",
      "Epoch 215 Loss 0.0302\n",
      "Time taken for 1 epoch 3.1515376567840576 sec\n",
      "\n",
      "Epoch 216 Batch 0 Loss 0.0002\n",
      "Epoch 216 Batch 10 Loss 0.0095\n",
      "Epoch 216 Batch 20 Loss 0.0012\n",
      "Epoch 216 Loss 0.0299\n",
      "Time taken for 1 epoch 3.2072832584381104 sec\n",
      "\n",
      "Epoch 217 Batch 0 Loss 0.0002\n",
      "Epoch 217 Batch 10 Loss 0.0092\n",
      "Epoch 217 Batch 20 Loss 0.0012\n",
      "Epoch 217 Loss 0.0296\n",
      "Time taken for 1 epoch 3.2305853366851807 sec\n",
      "\n",
      "Epoch 218 Batch 0 Loss 0.0002\n",
      "Epoch 218 Batch 10 Loss 0.0090\n",
      "Epoch 218 Batch 20 Loss 0.0012\n",
      "Epoch 218 Loss 0.0294\n",
      "Time taken for 1 epoch 3.7652697563171387 sec\n",
      "\n",
      "Epoch 219 Batch 0 Loss 0.0002\n",
      "Epoch 219 Batch 10 Loss 0.0087\n",
      "Epoch 219 Batch 20 Loss 0.0012\n",
      "Epoch 219 Loss 0.0291\n",
      "Time taken for 1 epoch 3.3324849605560303 sec\n",
      "\n",
      "Epoch 220 Batch 0 Loss 0.0002\n",
      "Epoch 220 Batch 10 Loss 0.0084\n",
      "Epoch 220 Batch 20 Loss 0.0011\n",
      "Epoch 220 Loss 0.0289\n",
      "Time taken for 1 epoch 3.1683504581451416 sec\n",
      "\n",
      "Epoch 221 Batch 0 Loss 0.0002\n",
      "Epoch 221 Batch 10 Loss 0.0082\n",
      "Epoch 221 Batch 20 Loss 0.0011\n",
      "Epoch 221 Loss 0.0286\n",
      "Time taken for 1 epoch 3.1066555976867676 sec\n",
      "\n",
      "Epoch 222 Batch 0 Loss 0.0002\n",
      "Epoch 222 Batch 10 Loss 0.0079\n",
      "Epoch 222 Batch 20 Loss 0.0011\n",
      "Epoch 222 Loss 0.0283\n",
      "Time taken for 1 epoch 3.2412686347961426 sec\n",
      "\n",
      "Epoch 223 Batch 0 Loss 0.0002\n",
      "Epoch 223 Batch 10 Loss 0.0077\n",
      "Epoch 223 Batch 20 Loss 0.0011\n",
      "Epoch 223 Loss 0.0281\n",
      "Time taken for 1 epoch 3.617213249206543 sec\n",
      "\n",
      "Epoch 224 Batch 0 Loss 0.0002\n",
      "Epoch 224 Batch 10 Loss 0.0074\n",
      "Epoch 224 Batch 20 Loss 0.0011\n",
      "Epoch 224 Loss 0.0278\n",
      "Time taken for 1 epoch 3.312462329864502 sec\n",
      "\n",
      "Epoch 225 Batch 0 Loss 0.0002\n",
      "Epoch 225 Batch 10 Loss 0.0072\n",
      "Epoch 225 Batch 20 Loss 0.0011\n",
      "Epoch 225 Loss 0.0276\n",
      "Time taken for 1 epoch 3.098496675491333 sec\n",
      "\n",
      "Epoch 226 Batch 0 Loss 0.0002\n",
      "Epoch 226 Batch 10 Loss 0.0070\n",
      "Epoch 226 Batch 20 Loss 0.0011\n",
      "Epoch 226 Loss 0.0273\n",
      "Time taken for 1 epoch 3.117906093597412 sec\n",
      "\n",
      "Epoch 227 Batch 0 Loss 0.0002\n",
      "Epoch 227 Batch 10 Loss 0.0067\n",
      "Epoch 227 Batch 20 Loss 0.0011\n",
      "Epoch 227 Loss 0.0271\n",
      "Time taken for 1 epoch 3.2331650257110596 sec\n",
      "\n",
      "Epoch 228 Batch 0 Loss 0.0002\n",
      "Epoch 228 Batch 10 Loss 0.0065\n",
      "Epoch 228 Batch 20 Loss 0.0011\n",
      "Epoch 228 Loss 0.0269\n",
      "Time taken for 1 epoch 3.92051362991333 sec\n",
      "\n",
      "Epoch 229 Batch 0 Loss 0.0002\n",
      "Epoch 229 Batch 10 Loss 0.0063\n",
      "Epoch 229 Batch 20 Loss 0.0011\n",
      "Epoch 229 Loss 0.0266\n",
      "Time taken for 1 epoch 3.304939031600952 sec\n",
      "\n",
      "Epoch 230 Batch 0 Loss 0.0002\n",
      "Epoch 230 Batch 10 Loss 0.0061\n",
      "Epoch 230 Batch 20 Loss 0.0011\n",
      "Epoch 230 Loss 0.0264\n",
      "Time taken for 1 epoch 3.070974826812744 sec\n",
      "\n",
      "Epoch 231 Batch 0 Loss 0.0002\n",
      "Epoch 231 Batch 10 Loss 0.0059\n",
      "Epoch 231 Batch 20 Loss 0.0010\n",
      "Epoch 231 Loss 0.0261\n",
      "Time taken for 1 epoch 3.0788543224334717 sec\n",
      "\n",
      "Epoch 232 Batch 0 Loss 0.0002\n",
      "Epoch 232 Batch 10 Loss 0.0057\n",
      "Epoch 232 Batch 20 Loss 0.0010\n",
      "Epoch 232 Loss 0.0259\n",
      "Time taken for 1 epoch 3.191901683807373 sec\n",
      "\n",
      "Epoch 233 Batch 0 Loss 0.0002\n",
      "Epoch 233 Batch 10 Loss 0.0055\n",
      "Epoch 233 Batch 20 Loss 0.0010\n",
      "Epoch 233 Loss 0.0257\n",
      "Time taken for 1 epoch 3.9133615493774414 sec\n",
      "\n",
      "Epoch 234 Batch 0 Loss 0.0002\n",
      "Epoch 234 Batch 10 Loss 0.0053\n",
      "Epoch 234 Batch 20 Loss 0.0010\n",
      "Epoch 234 Loss 0.0254\n",
      "Time taken for 1 epoch 3.171919345855713 sec\n",
      "\n",
      "Epoch 235 Batch 0 Loss 0.0002\n",
      "Epoch 235 Batch 10 Loss 0.0052\n",
      "Epoch 235 Batch 20 Loss 0.0010\n",
      "Epoch 235 Loss 0.0252\n",
      "Time taken for 1 epoch 3.0486481189727783 sec\n",
      "\n",
      "Epoch 236 Batch 0 Loss 0.0002\n",
      "Epoch 236 Batch 10 Loss 0.0050\n",
      "Epoch 236 Batch 20 Loss 0.0010\n",
      "Epoch 236 Loss 0.0250\n",
      "Time taken for 1 epoch 3.176912307739258 sec\n",
      "\n",
      "Epoch 237 Batch 0 Loss 0.0002\n",
      "Epoch 237 Batch 10 Loss 0.0048\n",
      "Epoch 237 Batch 20 Loss 0.0010\n",
      "Epoch 237 Loss 0.0248\n",
      "Time taken for 1 epoch 3.2564334869384766 sec\n",
      "\n",
      "Epoch 238 Batch 0 Loss 0.0002\n",
      "Epoch 238 Batch 10 Loss 0.0047\n",
      "Epoch 238 Batch 20 Loss 0.0010\n",
      "Epoch 238 Loss 0.0245\n",
      "Time taken for 1 epoch 3.770960807800293 sec\n",
      "\n",
      "Epoch 239 Batch 0 Loss 0.0002\n",
      "Epoch 239 Batch 10 Loss 0.0045\n",
      "Epoch 239 Batch 20 Loss 0.0010\n",
      "Epoch 239 Loss 0.0243\n",
      "Time taken for 1 epoch 3.1593172550201416 sec\n",
      "\n",
      "Epoch 240 Batch 0 Loss 0.0002\n",
      "Epoch 240 Batch 10 Loss 0.0043\n",
      "Epoch 240 Batch 20 Loss 0.0010\n",
      "Epoch 240 Loss 0.0241\n",
      "Time taken for 1 epoch 3.0357179641723633 sec\n",
      "\n",
      "Epoch 241 Batch 0 Loss 0.0002\n",
      "Epoch 241 Batch 10 Loss 0.0042\n",
      "Epoch 241 Batch 20 Loss 0.0010\n",
      "Epoch 241 Loss 0.0239\n",
      "Time taken for 1 epoch 3.1913766860961914 sec\n",
      "\n",
      "Epoch 242 Batch 0 Loss 0.0002\n",
      "Epoch 242 Batch 10 Loss 0.0040\n",
      "Epoch 242 Batch 20 Loss 0.0010\n",
      "Epoch 242 Loss 0.0237\n",
      "Time taken for 1 epoch 3.376765251159668 sec\n",
      "\n",
      "Epoch 243 Batch 0 Loss 0.0002\n",
      "Epoch 243 Batch 10 Loss 0.0039\n",
      "Epoch 243 Batch 20 Loss 0.0010\n",
      "Epoch 243 Loss 0.0235\n",
      "Time taken for 1 epoch 3.554621696472168 sec\n",
      "\n",
      "Epoch 244 Batch 0 Loss 0.0002\n",
      "Epoch 244 Batch 10 Loss 0.0038\n",
      "Epoch 244 Batch 20 Loss 0.0010\n",
      "Epoch 244 Loss 0.0232\n",
      "Time taken for 1 epoch 3.1857807636260986 sec\n",
      "\n",
      "Epoch 245 Batch 0 Loss 0.0002\n",
      "Epoch 245 Batch 10 Loss 0.0036\n",
      "Epoch 245 Batch 20 Loss 0.0009\n",
      "Epoch 245 Loss 0.0230\n",
      "Time taken for 1 epoch 3.089766263961792 sec\n",
      "\n",
      "Epoch 246 Batch 0 Loss 0.0002\n",
      "Epoch 246 Batch 10 Loss 0.0035\n",
      "Epoch 246 Batch 20 Loss 0.0009\n",
      "Epoch 246 Loss 0.0228\n",
      "Time taken for 1 epoch 3.2857718467712402 sec\n",
      "\n",
      "Epoch 247 Batch 0 Loss 0.0002\n",
      "Epoch 247 Batch 10 Loss 0.0034\n",
      "Epoch 247 Batch 20 Loss 0.0009\n",
      "Epoch 247 Loss 0.0226\n",
      "Time taken for 1 epoch 3.4496874809265137 sec\n",
      "\n",
      "Epoch 248 Batch 0 Loss 0.0002\n",
      "Epoch 248 Batch 10 Loss 0.0033\n",
      "Epoch 248 Batch 20 Loss 0.0009\n",
      "Epoch 248 Loss 0.0224\n",
      "Time taken for 1 epoch 3.3987061977386475 sec\n",
      "\n",
      "Epoch 249 Batch 0 Loss 0.0002\n",
      "Epoch 249 Batch 10 Loss 0.0032\n",
      "Epoch 249 Batch 20 Loss 0.0009\n",
      "Epoch 249 Loss 0.0222\n",
      "Time taken for 1 epoch 3.264523506164551 sec\n",
      "\n",
      "Epoch 250 Batch 0 Loss 0.0002\n",
      "Epoch 250 Batch 10 Loss 0.0030\n",
      "Epoch 250 Batch 20 Loss 0.0009\n",
      "Epoch 250 Loss 0.0220\n",
      "Time taken for 1 epoch 3.1863327026367188 sec\n",
      "\n",
      "Epoch 251 Batch 0 Loss 0.0002\n",
      "Epoch 251 Batch 10 Loss 0.0029\n",
      "Epoch 251 Batch 20 Loss 0.0009\n",
      "Epoch 251 Loss 0.0218\n",
      "Time taken for 1 epoch 3.2352559566497803 sec\n",
      "\n",
      "Epoch 252 Batch 0 Loss 0.0002\n",
      "Epoch 252 Batch 10 Loss 0.0028\n",
      "Epoch 252 Batch 20 Loss 0.0009\n",
      "Epoch 252 Loss 0.0216\n",
      "Time taken for 1 epoch 3.80840802192688 sec\n",
      "\n",
      "Epoch 253 Batch 0 Loss 0.0002\n",
      "Epoch 253 Batch 10 Loss 0.0027\n",
      "Epoch 253 Batch 20 Loss 0.0009\n",
      "Epoch 253 Loss 0.0214\n",
      "Time taken for 1 epoch 3.429481029510498 sec\n",
      "\n",
      "Epoch 254 Batch 0 Loss 0.0002\n",
      "Epoch 254 Batch 10 Loss 0.0026\n",
      "Epoch 254 Batch 20 Loss 0.0009\n",
      "Epoch 254 Loss 0.0212\n",
      "Time taken for 1 epoch 3.065613031387329 sec\n",
      "\n",
      "Epoch 255 Batch 0 Loss 0.0002\n",
      "Epoch 255 Batch 10 Loss 0.0026\n",
      "Epoch 255 Batch 20 Loss 0.0009\n",
      "Epoch 255 Loss 0.0210\n",
      "Time taken for 1 epoch 3.120206594467163 sec\n",
      "\n",
      "Epoch 256 Batch 0 Loss 0.0002\n",
      "Epoch 256 Batch 10 Loss 0.0025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 256 Batch 20 Loss 0.0009\n",
      "Epoch 256 Loss 0.0208\n",
      "Time taken for 1 epoch 3.1859841346740723 sec\n",
      "\n",
      "Epoch 257 Batch 0 Loss 0.0002\n",
      "Epoch 257 Batch 10 Loss 0.0024\n",
      "Epoch 257 Batch 20 Loss 0.0009\n",
      "Epoch 257 Loss 0.0206\n",
      "Time taken for 1 epoch 3.886188268661499 sec\n",
      "\n",
      "Epoch 258 Batch 0 Loss 0.0002\n",
      "Epoch 258 Batch 10 Loss 0.0023\n",
      "Epoch 258 Batch 20 Loss 0.0009\n",
      "Epoch 258 Loss 0.0205\n",
      "Time taken for 1 epoch 3.219024181365967 sec\n",
      "\n",
      "Epoch 259 Batch 0 Loss 0.0002\n",
      "Epoch 259 Batch 10 Loss 0.0022\n",
      "Epoch 259 Batch 20 Loss 0.0009\n",
      "Epoch 259 Loss 0.0203\n",
      "Time taken for 1 epoch 3.087151527404785 sec\n",
      "\n",
      "Epoch 260 Batch 0 Loss 0.0002\n",
      "Epoch 260 Batch 10 Loss 0.0021\n",
      "Epoch 260 Batch 20 Loss 0.0009\n",
      "Epoch 260 Loss 0.0201\n",
      "Time taken for 1 epoch 3.067416191101074 sec\n",
      "\n",
      "Epoch 261 Batch 0 Loss 0.0002\n",
      "Epoch 261 Batch 10 Loss 0.0021\n",
      "Epoch 261 Batch 20 Loss 0.0009\n",
      "Epoch 261 Loss 0.0199\n",
      "Time taken for 1 epoch 3.2468130588531494 sec\n",
      "\n",
      "Epoch 262 Batch 0 Loss 0.0002\n",
      "Epoch 262 Batch 10 Loss 0.0020\n",
      "Epoch 262 Batch 20 Loss 0.0009\n",
      "Epoch 262 Loss 0.0197\n",
      "Time taken for 1 epoch 4.040151119232178 sec\n",
      "\n",
      "Epoch 263 Batch 0 Loss 0.0002\n",
      "Epoch 263 Batch 10 Loss 0.0019\n",
      "Epoch 263 Batch 20 Loss 0.0009\n",
      "Epoch 263 Loss 0.0195\n",
      "Time taken for 1 epoch 3.3466928005218506 sec\n",
      "\n",
      "Epoch 264 Batch 0 Loss 0.0002\n",
      "Epoch 264 Batch 10 Loss 0.0019\n",
      "Epoch 264 Batch 20 Loss 0.0009\n",
      "Epoch 264 Loss 0.0194\n",
      "Time taken for 1 epoch 3.2494611740112305 sec\n",
      "\n",
      "Epoch 265 Batch 0 Loss 0.0002\n",
      "Epoch 265 Batch 10 Loss 0.0018\n",
      "Epoch 265 Batch 20 Loss 0.0009\n",
      "Epoch 265 Loss 0.0192\n",
      "Time taken for 1 epoch 3.606626510620117 sec\n",
      "\n",
      "Epoch 266 Batch 0 Loss 0.0002\n",
      "Epoch 266 Batch 10 Loss 0.0017\n",
      "Epoch 266 Batch 20 Loss 0.0008\n",
      "Epoch 266 Loss 0.0190\n",
      "Time taken for 1 epoch 4.336272954940796 sec\n",
      "\n",
      "Epoch 267 Batch 0 Loss 0.0002\n",
      "Epoch 267 Batch 10 Loss 0.0017\n",
      "Epoch 267 Batch 20 Loss 0.0009\n",
      "Epoch 267 Loss 0.0188\n",
      "Time taken for 1 epoch 3.702942132949829 sec\n",
      "\n",
      "Epoch 268 Batch 0 Loss 0.0002\n",
      "Epoch 268 Batch 10 Loss 0.0016\n",
      "Epoch 268 Batch 20 Loss 0.0009\n",
      "Epoch 268 Loss 0.0187\n",
      "Time taken for 1 epoch 3.620375156402588 sec\n",
      "\n",
      "Epoch 269 Batch 0 Loss 0.0002\n",
      "Epoch 269 Batch 10 Loss 0.0016\n",
      "Epoch 269 Batch 20 Loss 0.0009\n",
      "Epoch 269 Loss 0.0185\n",
      "Time taken for 1 epoch 3.215782403945923 sec\n",
      "\n",
      "Epoch 270 Batch 0 Loss 0.0002\n",
      "Epoch 270 Batch 10 Loss 0.0015\n",
      "Epoch 270 Batch 20 Loss 0.0008\n",
      "Epoch 270 Loss 0.0183\n",
      "Time taken for 1 epoch 3.650094747543335 sec\n",
      "\n",
      "Epoch 271 Batch 0 Loss 0.0002\n",
      "Epoch 271 Batch 10 Loss 0.0015\n",
      "Epoch 271 Batch 20 Loss 0.0008\n",
      "Epoch 271 Loss 0.0182\n",
      "Time taken for 1 epoch 3.942772388458252 sec\n",
      "\n",
      "Epoch 272 Batch 0 Loss 0.0002\n",
      "Epoch 272 Batch 10 Loss 0.0014\n",
      "Epoch 272 Batch 20 Loss 0.0009\n",
      "Epoch 272 Loss 0.0180\n",
      "Time taken for 1 epoch 3.226595878601074 sec\n",
      "\n",
      "Epoch 273 Batch 0 Loss 0.0002\n",
      "Epoch 273 Batch 10 Loss 0.0014\n",
      "Epoch 273 Batch 20 Loss 0.0009\n",
      "Epoch 273 Loss 0.0178\n",
      "Time taken for 1 epoch 3.099419116973877 sec\n",
      "\n",
      "Epoch 274 Batch 0 Loss 0.0002\n",
      "Epoch 274 Batch 10 Loss 0.0013\n",
      "Epoch 274 Batch 20 Loss 0.0008\n",
      "Epoch 274 Loss 0.0177\n",
      "Time taken for 1 epoch 3.0759057998657227 sec\n",
      "\n",
      "Epoch 275 Batch 0 Loss 0.0002\n",
      "Epoch 275 Batch 10 Loss 0.0013\n",
      "Epoch 275 Batch 20 Loss 0.0008\n",
      "Epoch 275 Loss 0.0175\n",
      "Time taken for 1 epoch 3.659184694290161 sec\n",
      "\n",
      "Epoch 276 Batch 0 Loss 0.0002\n",
      "Epoch 276 Batch 10 Loss 0.0013\n",
      "Epoch 276 Batch 20 Loss 0.0008\n",
      "Epoch 276 Loss 0.0174\n",
      "Time taken for 1 epoch 3.471475839614868 sec\n",
      "\n",
      "Epoch 277 Batch 0 Loss 0.0002\n",
      "Epoch 277 Batch 10 Loss 0.0012\n",
      "Epoch 277 Batch 20 Loss 0.0008\n",
      "Epoch 277 Loss 0.0172\n",
      "Time taken for 1 epoch 3.25026535987854 sec\n",
      "\n",
      "Epoch 278 Batch 0 Loss 0.0002\n",
      "Epoch 278 Batch 10 Loss 0.0012\n",
      "Epoch 278 Batch 20 Loss 0.0008\n",
      "Epoch 278 Loss 0.0170\n",
      "Time taken for 1 epoch 3.11071515083313 sec\n",
      "\n",
      "Epoch 279 Batch 0 Loss 0.0002\n",
      "Epoch 279 Batch 10 Loss 0.0011\n",
      "Epoch 279 Batch 20 Loss 0.0008\n",
      "Epoch 279 Loss 0.0169\n",
      "Time taken for 1 epoch 3.1078577041625977 sec\n",
      "\n",
      "Epoch 280 Batch 0 Loss 0.0002\n",
      "Epoch 280 Batch 10 Loss 0.0011\n",
      "Epoch 280 Batch 20 Loss 0.0008\n",
      "Epoch 280 Loss 0.0167\n",
      "Time taken for 1 epoch 3.835207462310791 sec\n",
      "\n",
      "Epoch 281 Batch 0 Loss 0.0002\n",
      "Epoch 281 Batch 10 Loss 0.0010\n",
      "Epoch 281 Batch 20 Loss 0.0008\n",
      "Epoch 281 Loss 0.0166\n",
      "Time taken for 1 epoch 3.3525614738464355 sec\n",
      "\n",
      "Epoch 282 Batch 0 Loss 0.0002\n",
      "Epoch 282 Batch 10 Loss 0.0010\n",
      "Epoch 282 Batch 20 Loss 0.0008\n",
      "Epoch 282 Loss 0.0164\n",
      "Time taken for 1 epoch 3.3082094192504883 sec\n",
      "\n",
      "Epoch 283 Batch 0 Loss 0.0002\n",
      "Epoch 283 Batch 10 Loss 0.0010\n",
      "Epoch 283 Batch 20 Loss 0.0008\n",
      "Epoch 283 Loss 0.0162\n",
      "Time taken for 1 epoch 3.091174840927124 sec\n",
      "\n",
      "Epoch 284 Batch 0 Loss 0.0002\n",
      "Epoch 284 Batch 10 Loss 0.0009\n",
      "Epoch 284 Batch 20 Loss 0.0008\n",
      "Epoch 284 Loss 0.0161\n",
      "Time taken for 1 epoch 3.0734059810638428 sec\n",
      "\n",
      "Epoch 285 Batch 0 Loss 0.0002\n",
      "Epoch 285 Batch 10 Loss 0.0009\n",
      "Epoch 285 Batch 20 Loss 0.0008\n",
      "Epoch 285 Loss 0.0159\n",
      "Time taken for 1 epoch 3.973815441131592 sec\n",
      "\n",
      "Epoch 286 Batch 0 Loss 0.0002\n",
      "Epoch 286 Batch 10 Loss 0.0009\n",
      "Epoch 286 Batch 20 Loss 0.0008\n",
      "Epoch 286 Loss 0.0158\n",
      "Time taken for 1 epoch 3.1366512775421143 sec\n",
      "\n",
      "Epoch 287 Batch 0 Loss 0.0002\n",
      "Epoch 287 Batch 10 Loss 0.0008\n",
      "Epoch 287 Batch 20 Loss 0.0007\n",
      "Epoch 287 Loss 0.0156\n",
      "Time taken for 1 epoch 3.1899542808532715 sec\n",
      "\n",
      "Epoch 288 Batch 0 Loss 0.0002\n",
      "Epoch 288 Batch 10 Loss 0.0008\n",
      "Epoch 288 Batch 20 Loss 0.0007\n",
      "Epoch 288 Loss 0.0155\n",
      "Time taken for 1 epoch 3.0680510997772217 sec\n",
      "\n",
      "Epoch 289 Batch 0 Loss 0.0002\n",
      "Epoch 289 Batch 10 Loss 0.0008\n",
      "Epoch 289 Batch 20 Loss 0.0007\n",
      "Epoch 289 Loss 0.0153\n",
      "Time taken for 1 epoch 3.1767890453338623 sec\n",
      "\n",
      "Epoch 290 Batch 0 Loss 0.0002\n",
      "Epoch 290 Batch 10 Loss 0.0008\n",
      "Epoch 290 Batch 20 Loss 0.0007\n",
      "Epoch 290 Loss 0.0152\n",
      "Time taken for 1 epoch 3.9283130168914795 sec\n",
      "\n",
      "Epoch 291 Batch 0 Loss 0.0002\n",
      "Epoch 291 Batch 10 Loss 0.0007\n",
      "Epoch 291 Batch 20 Loss 0.0007\n",
      "Epoch 291 Loss 0.0150\n",
      "Time taken for 1 epoch 3.1040196418762207 sec\n",
      "\n",
      "Epoch 292 Batch 0 Loss 0.0002\n",
      "Epoch 292 Batch 10 Loss 0.0007\n",
      "Epoch 292 Batch 20 Loss 0.0007\n",
      "Epoch 292 Loss 0.0149\n",
      "Time taken for 1 epoch 3.1791999340057373 sec\n",
      "\n",
      "Epoch 293 Batch 0 Loss 0.0002\n",
      "Epoch 293 Batch 10 Loss 0.0007\n",
      "Epoch 293 Batch 20 Loss 0.0007\n",
      "Epoch 293 Loss 0.0147\n",
      "Time taken for 1 epoch 3.0719289779663086 sec\n",
      "\n",
      "Epoch 294 Batch 0 Loss 0.0002\n",
      "Epoch 294 Batch 10 Loss 0.0007\n",
      "Epoch 294 Batch 20 Loss 0.0007\n",
      "Epoch 294 Loss 0.0146\n",
      "Time taken for 1 epoch 3.3051300048828125 sec\n",
      "\n",
      "Epoch 295 Batch 0 Loss 0.0002\n",
      "Epoch 295 Batch 10 Loss 0.0007\n",
      "Epoch 295 Batch 20 Loss 0.0007\n",
      "Epoch 295 Loss 0.0144\n",
      "Time taken for 1 epoch 3.770310163497925 sec\n",
      "\n",
      "Epoch 296 Batch 0 Loss 0.0002\n",
      "Epoch 296 Batch 10 Loss 0.0006\n",
      "Epoch 296 Batch 20 Loss 0.0007\n",
      "Epoch 296 Loss 0.0143\n",
      "Time taken for 1 epoch 3.185711622238159 sec\n",
      "\n",
      "Epoch 297 Batch 0 Loss 0.0002\n",
      "Epoch 297 Batch 10 Loss 0.0006\n",
      "Epoch 297 Batch 20 Loss 0.0008\n",
      "Epoch 297 Loss 0.0141\n",
      "Time taken for 1 epoch 3.2163503170013428 sec\n",
      "\n",
      "Epoch 298 Batch 0 Loss 0.0002\n",
      "Epoch 298 Batch 10 Loss 0.0006\n",
      "Epoch 298 Batch 20 Loss 0.0008\n",
      "Epoch 298 Loss 0.0140\n",
      "Time taken for 1 epoch 3.110243320465088 sec\n",
      "\n",
      "Epoch 299 Batch 0 Loss 0.0002\n",
      "Epoch 299 Batch 10 Loss 0.0006\n",
      "Epoch 299 Batch 20 Loss 0.0007\n",
      "Epoch 299 Loss 0.0139\n",
      "Time taken for 1 epoch 3.444552183151245 sec\n",
      "\n",
      "Epoch 300 Batch 0 Loss 0.0002\n",
      "Epoch 300 Batch 10 Loss 0.0006\n",
      "Epoch 300 Batch 20 Loss 0.0007\n",
      "Epoch 300 Loss 0.0137\n",
      "Time taken for 1 epoch 3.5510237216949463 sec\n",
      "\n",
      "Epoch 301 Batch 0 Loss 0.0002\n",
      "Epoch 301 Batch 10 Loss 0.0006\n",
      "Epoch 301 Batch 20 Loss 0.0007\n",
      "Epoch 301 Loss 0.0136\n",
      "Time taken for 1 epoch 3.2477402687072754 sec\n",
      "\n",
      "Epoch 302 Batch 0 Loss 0.0002\n",
      "Epoch 302 Batch 10 Loss 0.0005\n",
      "Epoch 302 Batch 20 Loss 0.0007\n",
      "Epoch 302 Loss 0.0135\n",
      "Time taken for 1 epoch 3.1008524894714355 sec\n",
      "\n",
      "Epoch 303 Batch 0 Loss 0.0002\n",
      "Epoch 303 Batch 10 Loss 0.0005\n",
      "Epoch 303 Batch 20 Loss 0.0007\n",
      "Epoch 303 Loss 0.0133\n",
      "Time taken for 1 epoch 3.0830297470092773 sec\n",
      "\n",
      "Epoch 304 Batch 0 Loss 0.0002\n",
      "Epoch 304 Batch 10 Loss 0.0005\n",
      "Epoch 304 Batch 20 Loss 0.0007\n",
      "Epoch 304 Loss 0.0132\n",
      "Time taken for 1 epoch 3.5341713428497314 sec\n",
      "\n",
      "Epoch 305 Batch 0 Loss 0.0002\n",
      "Epoch 305 Batch 10 Loss 0.0005\n",
      "Epoch 305 Batch 20 Loss 0.0007\n",
      "Epoch 305 Loss 0.0131\n",
      "Time taken for 1 epoch 3.5295228958129883 sec\n",
      "\n",
      "Epoch 306 Batch 0 Loss 0.0002\n",
      "Epoch 306 Batch 10 Loss 0.0005\n",
      "Epoch 306 Batch 20 Loss 0.0007\n",
      "Epoch 306 Loss 0.0129\n",
      "Time taken for 1 epoch 3.231400728225708 sec\n",
      "\n",
      "Epoch 307 Batch 0 Loss 0.0002\n",
      "Epoch 307 Batch 10 Loss 0.0005\n",
      "Epoch 307 Batch 20 Loss 0.0007\n",
      "Epoch 307 Loss 0.0128\n",
      "Time taken for 1 epoch 3.0707709789276123 sec\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 308 Batch 0 Loss 0.0002\n",
      "Epoch 308 Batch 10 Loss 0.0005\n",
      "Epoch 308 Batch 20 Loss 0.0007\n",
      "Epoch 308 Loss 0.0127\n",
      "Time taken for 1 epoch 3.0841994285583496 sec\n",
      "\n",
      "Epoch 309 Batch 0 Loss 0.0002\n",
      "Epoch 309 Batch 10 Loss 0.0004\n",
      "Epoch 309 Batch 20 Loss 0.0007\n",
      "Epoch 309 Loss 0.0125\n",
      "Time taken for 1 epoch 3.7388062477111816 sec\n",
      "\n",
      "Epoch 310 Batch 0 Loss 0.0002\n",
      "Epoch 310 Batch 10 Loss 0.0004\n",
      "Epoch 310 Batch 20 Loss 0.0007\n",
      "Epoch 310 Loss 0.0124\n",
      "Time taken for 1 epoch 3.3433115482330322 sec\n",
      "\n",
      "Epoch 311 Batch 0 Loss 0.0002\n",
      "Epoch 311 Batch 10 Loss 0.0004\n",
      "Epoch 311 Batch 20 Loss 0.0008\n",
      "Epoch 311 Loss 0.0123\n",
      "Time taken for 1 epoch 3.19037127494812 sec\n",
      "\n",
      "Epoch 312 Batch 0 Loss 0.0002\n",
      "Epoch 312 Batch 10 Loss 0.0004\n",
      "Epoch 312 Batch 20 Loss 0.0007\n",
      "Epoch 312 Loss 0.0122\n",
      "Time taken for 1 epoch 3.059386968612671 sec\n",
      "\n",
      "Epoch 313 Batch 0 Loss 0.0002\n",
      "Epoch 313 Batch 10 Loss 0.0004\n",
      "Epoch 313 Batch 20 Loss 0.0007\n",
      "Epoch 313 Loss 0.0120\n",
      "Time taken for 1 epoch 3.0739493370056152 sec\n",
      "\n",
      "Epoch 314 Batch 0 Loss 0.0002\n",
      "Epoch 314 Batch 10 Loss 0.0004\n",
      "Epoch 314 Batch 20 Loss 0.0007\n",
      "Epoch 314 Loss 0.0119\n",
      "Time taken for 1 epoch 3.8962655067443848 sec\n",
      "\n",
      "Epoch 315 Batch 0 Loss 0.0002\n",
      "Epoch 315 Batch 10 Loss 0.0004\n",
      "Epoch 315 Batch 20 Loss 0.0007\n",
      "Epoch 315 Loss 0.0118\n",
      "Time taken for 1 epoch 3.1644632816314697 sec\n",
      "\n",
      "Epoch 316 Batch 0 Loss 0.0002\n",
      "Epoch 316 Batch 10 Loss 0.0004\n",
      "Epoch 316 Batch 20 Loss 0.0007\n",
      "Epoch 316 Loss 0.0117\n",
      "Time taken for 1 epoch 3.170546531677246 sec\n",
      "\n",
      "Epoch 317 Batch 0 Loss 0.0002\n",
      "Epoch 317 Batch 10 Loss 0.0004\n",
      "Epoch 317 Batch 20 Loss 0.0007\n",
      "Epoch 317 Loss 0.0115\n",
      "Time taken for 1 epoch 3.0578041076660156 sec\n",
      "\n",
      "Epoch 318 Batch 0 Loss 0.0002\n",
      "Epoch 318 Batch 10 Loss 0.0004\n",
      "Epoch 318 Batch 20 Loss 0.0007\n",
      "Epoch 318 Loss 0.0114\n",
      "Time taken for 1 epoch 3.243222951889038 sec\n",
      "\n",
      "Epoch 319 Batch 0 Loss 0.0002\n",
      "Epoch 319 Batch 10 Loss 0.0004\n",
      "Epoch 319 Batch 20 Loss 0.0007\n",
      "Epoch 319 Loss 0.0113\n",
      "Time taken for 1 epoch 3.927807331085205 sec\n",
      "\n",
      "Epoch 320 Batch 0 Loss 0.0002\n",
      "Epoch 320 Batch 10 Loss 0.0004\n",
      "Epoch 320 Batch 20 Loss 0.0007\n",
      "Epoch 320 Loss 0.0112\n",
      "Time taken for 1 epoch 3.1076016426086426 sec\n",
      "\n",
      "Epoch 321 Batch 0 Loss 0.0002\n",
      "Epoch 321 Batch 10 Loss 0.0003\n",
      "Epoch 321 Batch 20 Loss 0.0007\n",
      "Epoch 321 Loss 0.0111\n",
      "Time taken for 1 epoch 3.1713674068450928 sec\n",
      "\n",
      "Epoch 322 Batch 0 Loss 0.0002\n",
      "Epoch 322 Batch 10 Loss 0.0003\n",
      "Epoch 322 Batch 20 Loss 0.0007\n",
      "Epoch 322 Loss 0.0109\n",
      "Time taken for 1 epoch 3.133091449737549 sec\n",
      "\n",
      "Epoch 323 Batch 0 Loss 0.0002\n",
      "Epoch 323 Batch 10 Loss 0.0004\n",
      "Epoch 323 Batch 20 Loss 0.0007\n",
      "Epoch 323 Loss 0.0108\n",
      "Time taken for 1 epoch 3.238229513168335 sec\n",
      "\n",
      "Epoch 324 Batch 0 Loss 0.0002\n",
      "Epoch 324 Batch 10 Loss 0.0004\n",
      "Epoch 324 Batch 20 Loss 0.0007\n",
      "Epoch 324 Loss 0.0107\n",
      "Time taken for 1 epoch 3.7730400562286377 sec\n",
      "\n",
      "Epoch 325 Batch 0 Loss 0.0002\n",
      "Epoch 325 Batch 10 Loss 0.0004\n",
      "Epoch 325 Batch 20 Loss 0.0007\n",
      "Epoch 325 Loss 0.0106\n",
      "Time taken for 1 epoch 3.1575961112976074 sec\n",
      "\n",
      "Epoch 326 Batch 0 Loss 0.0002\n",
      "Epoch 326 Batch 10 Loss 0.0004\n",
      "Epoch 326 Batch 20 Loss 0.0007\n",
      "Epoch 326 Loss 0.0105\n",
      "Time taken for 1 epoch 3.557095527648926 sec\n",
      "\n",
      "Epoch 327 Batch 0 Loss 0.0002\n",
      "Epoch 327 Batch 10 Loss 0.0004\n",
      "Epoch 327 Batch 20 Loss 0.0007\n",
      "Epoch 327 Loss 0.0104\n",
      "Time taken for 1 epoch 3.3764801025390625 sec\n",
      "\n",
      "Epoch 328 Batch 0 Loss 0.0002\n",
      "Epoch 328 Batch 10 Loss 0.0004\n",
      "Epoch 328 Batch 20 Loss 0.0007\n",
      "Epoch 328 Loss 0.0103\n",
      "Time taken for 1 epoch 3.773041009902954 sec\n",
      "\n",
      "Epoch 329 Batch 0 Loss 0.0002\n",
      "Epoch 329 Batch 10 Loss 0.0004\n",
      "Epoch 329 Batch 20 Loss 0.0007\n",
      "Epoch 329 Loss 0.0102\n",
      "Time taken for 1 epoch 3.457651138305664 sec\n",
      "\n",
      "Epoch 330 Batch 0 Loss 0.0002\n",
      "Epoch 330 Batch 10 Loss 0.0004\n",
      "Epoch 330 Batch 20 Loss 0.0007\n",
      "Epoch 330 Loss 0.0101\n",
      "Time taken for 1 epoch 3.1850745677948 sec\n",
      "\n",
      "Epoch 331 Batch 0 Loss 0.0002\n",
      "Epoch 331 Batch 10 Loss 0.0004\n",
      "Epoch 331 Batch 20 Loss 0.0007\n",
      "Epoch 331 Loss 0.0100\n",
      "Time taken for 1 epoch 3.099210500717163 sec\n",
      "\n",
      "Epoch 332 Batch 0 Loss 0.0002\n",
      "Epoch 332 Batch 10 Loss 0.0004\n",
      "Epoch 332 Batch 20 Loss 0.0007\n",
      "Epoch 332 Loss 0.0099\n",
      "Time taken for 1 epoch 3.10526180267334 sec\n",
      "\n",
      "Epoch 333 Batch 0 Loss 0.0002\n",
      "Epoch 333 Batch 10 Loss 0.0004\n",
      "Epoch 333 Batch 20 Loss 0.0007\n",
      "Epoch 333 Loss 0.0098\n",
      "Time taken for 1 epoch 3.964418649673462 sec\n",
      "\n",
      "Epoch 334 Batch 0 Loss 0.0002\n",
      "Epoch 334 Batch 10 Loss 0.0004\n",
      "Epoch 334 Batch 20 Loss 0.0006\n",
      "Epoch 334 Loss 0.0097\n",
      "Time taken for 1 epoch 3.2720587253570557 sec\n",
      "\n",
      "Epoch 335 Batch 0 Loss 0.0002\n",
      "Epoch 335 Batch 10 Loss 0.0003\n",
      "Epoch 335 Batch 20 Loss 0.0006\n",
      "Epoch 335 Loss 0.0096\n",
      "Time taken for 1 epoch 3.2998435497283936 sec\n",
      "\n",
      "Epoch 336 Batch 0 Loss 0.0002\n",
      "Epoch 336 Batch 10 Loss 0.0003\n",
      "Epoch 336 Batch 20 Loss 0.0006\n",
      "Epoch 336 Loss 0.0095\n",
      "Time taken for 1 epoch 3.1611602306365967 sec\n",
      "\n",
      "Epoch 337 Batch 0 Loss 0.0002\n",
      "Epoch 337 Batch 10 Loss 0.0003\n",
      "Epoch 337 Batch 20 Loss 0.0006\n",
      "Epoch 337 Loss 0.0094\n",
      "Time taken for 1 epoch 3.061872720718384 sec\n",
      "\n",
      "Epoch 338 Batch 0 Loss 0.0002\n",
      "Epoch 338 Batch 10 Loss 0.0003\n",
      "Epoch 338 Batch 20 Loss 0.0006\n",
      "Epoch 338 Loss 0.0092\n",
      "Time taken for 1 epoch 4.904729604721069 sec\n",
      "\n",
      "Epoch 339 Batch 0 Loss 0.0002\n",
      "Epoch 339 Batch 10 Loss 0.0003\n",
      "Epoch 339 Batch 20 Loss 0.0006\n",
      "Epoch 339 Loss 0.0092\n",
      "Time taken for 1 epoch 4.958548069000244 sec\n",
      "\n",
      "Epoch 340 Batch 0 Loss 0.0002\n",
      "Epoch 340 Batch 10 Loss 0.0004\n",
      "Epoch 340 Batch 20 Loss 0.0006\n",
      "Epoch 340 Loss 0.0091\n",
      "Time taken for 1 epoch 3.661309242248535 sec\n",
      "\n",
      "Epoch 341 Batch 0 Loss 0.0002\n",
      "Epoch 341 Batch 10 Loss 0.0003\n",
      "Epoch 341 Batch 20 Loss 0.0006\n",
      "Epoch 341 Loss 0.0090\n",
      "Time taken for 1 epoch 3.236825704574585 sec\n",
      "\n",
      "Epoch 342 Batch 0 Loss 0.0002\n",
      "Epoch 342 Batch 10 Loss 0.0003\n",
      "Epoch 342 Batch 20 Loss 0.0006\n",
      "Epoch 342 Loss 0.0089\n",
      "Time taken for 1 epoch 3.8078856468200684 sec\n",
      "\n",
      "Epoch 343 Batch 0 Loss 0.0002\n",
      "Epoch 343 Batch 10 Loss 0.0003\n",
      "Epoch 343 Batch 20 Loss 0.0006\n",
      "Epoch 343 Loss 0.0088\n",
      "Time taken for 1 epoch 3.4551432132720947 sec\n",
      "\n",
      "Epoch 344 Batch 0 Loss 0.0002\n",
      "Epoch 344 Batch 10 Loss 0.0003\n",
      "Epoch 344 Batch 20 Loss 0.0006\n",
      "Epoch 344 Loss 0.0087\n",
      "Time taken for 1 epoch 3.137505292892456 sec\n",
      "\n",
      "Epoch 345 Batch 0 Loss 0.0002\n",
      "Epoch 345 Batch 10 Loss 0.0003\n",
      "Epoch 345 Batch 20 Loss 0.0006\n",
      "Epoch 345 Loss 0.0086\n",
      "Time taken for 1 epoch 3.259657621383667 sec\n",
      "\n",
      "Epoch 346 Batch 0 Loss 0.0002\n",
      "Epoch 346 Batch 10 Loss 0.0003\n",
      "Epoch 346 Batch 20 Loss 0.0006\n",
      "Epoch 346 Loss 0.0085\n",
      "Time taken for 1 epoch 3.317092180252075 sec\n",
      "\n",
      "Epoch 347 Batch 0 Loss 0.0002\n",
      "Epoch 347 Batch 10 Loss 0.0003\n",
      "Epoch 347 Batch 20 Loss 0.0006\n",
      "Epoch 347 Loss 0.0084\n",
      "Time taken for 1 epoch 3.6892542839050293 sec\n",
      "\n",
      "Epoch 348 Batch 0 Loss 0.0002\n",
      "Epoch 348 Batch 10 Loss 0.0003\n",
      "Epoch 348 Batch 20 Loss 0.0006\n",
      "Epoch 348 Loss 0.0083\n",
      "Time taken for 1 epoch 3.0990641117095947 sec\n",
      "\n",
      "Epoch 349 Batch 0 Loss 0.0002\n",
      "Epoch 349 Batch 10 Loss 0.0004\n",
      "Epoch 349 Batch 20 Loss 0.0007\n",
      "Epoch 349 Loss 0.0082\n",
      "Time taken for 1 epoch 3.1372525691986084 sec\n",
      "\n",
      "Epoch 350 Batch 0 Loss 0.0002\n",
      "Epoch 350 Batch 10 Loss 0.0003\n",
      "Epoch 350 Batch 20 Loss 0.0006\n",
      "Epoch 350 Loss 0.0081\n",
      "Time taken for 1 epoch 3.7393617630004883 sec\n",
      "\n",
      "Epoch 351 Batch 0 Loss 0.0002\n",
      "Epoch 351 Batch 10 Loss 0.0003\n",
      "Epoch 351 Batch 20 Loss 0.0006\n",
      "Epoch 351 Loss 0.0080\n",
      "Time taken for 1 epoch 3.948577404022217 sec\n",
      "\n",
      "Epoch 352 Batch 0 Loss 0.0002\n",
      "Epoch 352 Batch 10 Loss 0.0004\n",
      "Epoch 352 Batch 20 Loss 0.0006\n",
      "Epoch 352 Loss 0.0080\n",
      "Time taken for 1 epoch 3.6994447708129883 sec\n",
      "\n",
      "Epoch 353 Batch 0 Loss 0.0002\n",
      "Epoch 353 Batch 10 Loss 0.0004\n",
      "Epoch 353 Batch 20 Loss 0.0006\n",
      "Epoch 353 Loss 0.0079\n",
      "Time taken for 1 epoch 3.197051763534546 sec\n",
      "\n",
      "Epoch 354 Batch 0 Loss 0.0002\n",
      "Epoch 354 Batch 10 Loss 0.0003\n",
      "Epoch 354 Batch 20 Loss 0.0006\n",
      "Epoch 354 Loss 0.0078\n",
      "Time taken for 1 epoch 3.2703559398651123 sec\n",
      "\n",
      "Epoch 355 Batch 0 Loss 0.0002\n",
      "Epoch 355 Batch 10 Loss 0.0003\n",
      "Epoch 355 Batch 20 Loss 0.0006\n",
      "Epoch 355 Loss 0.0077\n",
      "Time taken for 1 epoch 3.1199965476989746 sec\n",
      "\n",
      "Epoch 356 Batch 0 Loss 0.0002\n",
      "Epoch 356 Batch 10 Loss 0.0003\n",
      "Epoch 356 Batch 20 Loss 0.0006\n",
      "Epoch 356 Loss 0.0076\n",
      "Time taken for 1 epoch 3.871208667755127 sec\n",
      "\n",
      "Epoch 357 Batch 0 Loss 0.0002\n",
      "Epoch 357 Batch 10 Loss 0.0003\n",
      "Epoch 357 Batch 20 Loss 0.0006\n",
      "Epoch 357 Loss 0.0076\n",
      "Time taken for 1 epoch 3.3800292015075684 sec\n",
      "\n",
      "Epoch 358 Batch 0 Loss 0.0002\n",
      "Epoch 358 Batch 10 Loss 0.0003\n",
      "Epoch 358 Batch 20 Loss 0.0006\n",
      "Epoch 358 Loss 0.0075\n",
      "Time taken for 1 epoch 3.175210475921631 sec\n",
      "\n",
      "Epoch 359 Batch 0 Loss 0.0002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 359 Batch 10 Loss 0.0003\n",
      "Epoch 359 Batch 20 Loss 0.0006\n",
      "Epoch 359 Loss 0.0074\n",
      "Time taken for 1 epoch 3.250692129135132 sec\n",
      "\n",
      "Epoch 360 Batch 0 Loss 0.0002\n",
      "Epoch 360 Batch 10 Loss 0.0002\n",
      "Epoch 360 Batch 20 Loss 0.0006\n",
      "Epoch 360 Loss 0.0073\n",
      "Time taken for 1 epoch 3.235609531402588 sec\n",
      "\n",
      "Epoch 361 Batch 0 Loss 0.0002\n",
      "Epoch 361 Batch 10 Loss 0.0003\n",
      "Epoch 361 Batch 20 Loss 0.0006\n",
      "Epoch 361 Loss 0.0072\n",
      "Time taken for 1 epoch 3.6668031215667725 sec\n",
      "\n",
      "Epoch 362 Batch 0 Loss 0.0002\n",
      "Epoch 362 Batch 10 Loss 0.0003\n",
      "Epoch 362 Batch 20 Loss 0.0006\n",
      "Epoch 362 Loss 0.0072\n",
      "Time taken for 1 epoch 3.419567108154297 sec\n",
      "\n",
      "Epoch 363 Batch 0 Loss 0.0002\n",
      "Epoch 363 Batch 10 Loss 0.0003\n",
      "Epoch 363 Batch 20 Loss 0.0006\n",
      "Epoch 363 Loss 0.0071\n",
      "Time taken for 1 epoch 3.1386044025421143 sec\n",
      "\n",
      "Epoch 364 Batch 0 Loss 0.0002\n",
      "Epoch 364 Batch 10 Loss 0.0003\n",
      "Epoch 364 Batch 20 Loss 0.0006\n",
      "Epoch 364 Loss 0.0070\n",
      "Time taken for 1 epoch 3.3177425861358643 sec\n",
      "\n",
      "Epoch 365 Batch 0 Loss 0.0002\n",
      "Epoch 365 Batch 10 Loss 0.0003\n",
      "Epoch 365 Batch 20 Loss 0.0006\n",
      "Epoch 365 Loss 0.0069\n",
      "Time taken for 1 epoch 3.5665011405944824 sec\n",
      "\n",
      "Epoch 366 Batch 0 Loss 0.0002\n",
      "Epoch 366 Batch 10 Loss 0.0003\n",
      "Epoch 366 Batch 20 Loss 0.0006\n",
      "Epoch 366 Loss 0.0068\n",
      "Time taken for 1 epoch 3.489057779312134 sec\n",
      "\n",
      "Epoch 367 Batch 0 Loss 0.0002\n",
      "Epoch 367 Batch 10 Loss 0.0003\n",
      "Epoch 367 Batch 20 Loss 0.0006\n",
      "Epoch 367 Loss 0.0068\n",
      "Time taken for 1 epoch 3.0267632007598877 sec\n",
      "\n",
      "Epoch 368 Batch 0 Loss 0.0002\n",
      "Epoch 368 Batch 10 Loss 0.0003\n",
      "Epoch 368 Batch 20 Loss 0.0006\n",
      "Epoch 368 Loss 0.0067\n",
      "Time taken for 1 epoch 3.071655035018921 sec\n",
      "\n",
      "Epoch 369 Batch 0 Loss 0.0002\n",
      "Epoch 369 Batch 10 Loss 0.0003\n",
      "Epoch 369 Batch 20 Loss 0.0006\n",
      "Epoch 369 Loss 0.0066\n",
      "Time taken for 1 epoch 3.157139301300049 sec\n",
      "\n",
      "Epoch 370 Batch 0 Loss 0.0002\n",
      "Epoch 370 Batch 10 Loss 0.0002\n",
      "Epoch 370 Batch 20 Loss 0.0005\n",
      "Epoch 370 Loss 0.0066\n",
      "Time taken for 1 epoch 3.704451084136963 sec\n",
      "\n",
      "Epoch 371 Batch 0 Loss 0.0002\n",
      "Epoch 371 Batch 10 Loss 0.0003\n",
      "Epoch 371 Batch 20 Loss 0.0006\n",
      "Epoch 371 Loss 0.0065\n",
      "Time taken for 1 epoch 3.4121134281158447 sec\n",
      "\n",
      "Epoch 372 Batch 0 Loss 0.0002\n",
      "Epoch 372 Batch 10 Loss 0.0003\n",
      "Epoch 372 Batch 20 Loss 0.0006\n",
      "Epoch 372 Loss 0.0064\n",
      "Time taken for 1 epoch 3.077899217605591 sec\n",
      "\n",
      "Epoch 373 Batch 0 Loss 0.0002\n",
      "Epoch 373 Batch 10 Loss 0.0003\n",
      "Epoch 373 Batch 20 Loss 0.0005\n",
      "Epoch 373 Loss 0.0064\n",
      "Time taken for 1 epoch 3.073788642883301 sec\n",
      "\n",
      "Epoch 374 Batch 0 Loss 0.0002\n",
      "Epoch 374 Batch 10 Loss 0.0005\n",
      "Epoch 374 Batch 20 Loss 0.0007\n",
      "Epoch 374 Loss 0.0063\n",
      "Time taken for 1 epoch 3.5119636058807373 sec\n",
      "\n",
      "Epoch 375 Batch 0 Loss 0.0002\n",
      "Epoch 375 Batch 10 Loss 0.0003\n",
      "Epoch 375 Batch 20 Loss 0.0005\n",
      "Epoch 375 Loss 0.0062\n",
      "Time taken for 1 epoch 4.135615348815918 sec\n",
      "\n",
      "Epoch 376 Batch 0 Loss 0.0002\n",
      "Epoch 376 Batch 10 Loss 0.0003\n",
      "Epoch 376 Batch 20 Loss 0.0006\n",
      "Epoch 376 Loss 0.0062\n",
      "Time taken for 1 epoch 3.4564383029937744 sec\n",
      "\n",
      "Epoch 377 Batch 0 Loss 0.0002\n",
      "Epoch 377 Batch 10 Loss 0.0004\n",
      "Epoch 377 Batch 20 Loss 0.0006\n",
      "Epoch 377 Loss 0.0061\n",
      "Time taken for 1 epoch 3.092156410217285 sec\n",
      "\n",
      "Epoch 378 Batch 0 Loss 0.0002\n",
      "Epoch 378 Batch 10 Loss 0.0002\n",
      "Epoch 378 Batch 20 Loss 0.0005\n",
      "Epoch 378 Loss 0.0061\n",
      "Time taken for 1 epoch 3.104584217071533 sec\n",
      "\n",
      "Epoch 379 Batch 0 Loss 0.0002\n",
      "Epoch 379 Batch 10 Loss 0.0003\n",
      "Epoch 379 Batch 20 Loss 0.0005\n",
      "Epoch 379 Loss 0.0060\n",
      "Time taken for 1 epoch 3.7397236824035645 sec\n",
      "\n",
      "Epoch 380 Batch 0 Loss 0.0002\n",
      "Epoch 380 Batch 10 Loss 0.0003\n",
      "Epoch 380 Batch 20 Loss 0.0006\n",
      "Epoch 380 Loss 0.0059\n",
      "Time taken for 1 epoch 3.8003053665161133 sec\n",
      "\n",
      "Epoch 381 Batch 0 Loss 0.0002\n",
      "Epoch 381 Batch 10 Loss 0.0001\n",
      "Epoch 381 Batch 20 Loss 0.0003\n",
      "Epoch 381 Loss 0.0059\n",
      "Time taken for 1 epoch 3.4102725982666016 sec\n",
      "\n",
      "Epoch 382 Batch 0 Loss 0.0003\n",
      "Epoch 382 Batch 10 Loss 0.0002\n",
      "Epoch 382 Batch 20 Loss 0.0006\n",
      "Epoch 382 Loss 0.0058\n",
      "Time taken for 1 epoch 3.385910987854004 sec\n",
      "\n",
      "Epoch 383 Batch 0 Loss 0.0002\n",
      "Epoch 383 Batch 10 Loss 0.0004\n",
      "Epoch 383 Batch 20 Loss 0.0006\n",
      "Epoch 383 Loss 0.0057\n",
      "Time taken for 1 epoch 3.4000914096832275 sec\n",
      "\n",
      "Epoch 384 Batch 0 Loss 0.0002\n",
      "Epoch 384 Batch 10 Loss 0.0004\n",
      "Epoch 384 Batch 20 Loss 0.0005\n",
      "Epoch 384 Loss 0.0057\n",
      "Time taken for 1 epoch 4.714132070541382 sec\n",
      "\n",
      "Epoch 385 Batch 0 Loss 0.0002\n",
      "Epoch 385 Batch 10 Loss 0.0003\n",
      "Epoch 385 Batch 20 Loss 0.0005\n",
      "Epoch 385 Loss 0.0056\n",
      "Time taken for 1 epoch 3.377742290496826 sec\n",
      "\n",
      "Epoch 386 Batch 0 Loss 0.0002\n",
      "Epoch 386 Batch 10 Loss 0.0003\n",
      "Epoch 386 Batch 20 Loss 0.0006\n",
      "Epoch 386 Loss 0.0056\n",
      "Time taken for 1 epoch 3.1756720542907715 sec\n",
      "\n",
      "Epoch 387 Batch 0 Loss 0.0002\n",
      "Epoch 387 Batch 10 Loss 0.0003\n",
      "Epoch 387 Batch 20 Loss 0.0006\n",
      "Epoch 387 Loss 0.0055\n",
      "Time taken for 1 epoch 3.3601129055023193 sec\n",
      "\n",
      "Epoch 388 Batch 0 Loss 0.0002\n",
      "Epoch 388 Batch 10 Loss 0.0004\n",
      "Epoch 388 Batch 20 Loss 0.0006\n",
      "Epoch 388 Loss 0.0054\n",
      "Time taken for 1 epoch 3.4467179775238037 sec\n",
      "\n",
      "Epoch 389 Batch 0 Loss 0.0002\n",
      "Epoch 389 Batch 10 Loss 0.0003\n",
      "Epoch 389 Batch 20 Loss 0.0006\n",
      "Epoch 389 Loss 0.0054\n",
      "Time taken for 1 epoch 3.5813255310058594 sec\n",
      "\n",
      "Epoch 390 Batch 0 Loss 0.0002\n",
      "Epoch 390 Batch 10 Loss 0.0003\n",
      "Epoch 390 Batch 20 Loss 0.0006\n",
      "Epoch 390 Loss 0.0053\n",
      "Time taken for 1 epoch 3.128588914871216 sec\n",
      "\n",
      "Epoch 391 Batch 0 Loss 0.0002\n",
      "Epoch 391 Batch 10 Loss 0.0004\n",
      "Epoch 391 Batch 20 Loss 0.0006\n",
      "Epoch 391 Loss 0.0053\n",
      "Time taken for 1 epoch 3.2766342163085938 sec\n",
      "\n",
      "Epoch 392 Batch 0 Loss 0.0002\n",
      "Epoch 392 Batch 10 Loss 0.0003\n",
      "Epoch 392 Batch 20 Loss 0.0006\n",
      "Epoch 392 Loss 0.0052\n",
      "Time taken for 1 epoch 3.1109883785247803 sec\n",
      "\n",
      "Epoch 393 Batch 0 Loss 0.0002\n",
      "Epoch 393 Batch 10 Loss 0.0003\n",
      "Epoch 393 Batch 20 Loss 0.0005\n",
      "Epoch 393 Loss 0.0052\n",
      "Time taken for 1 epoch 3.5752782821655273 sec\n",
      "\n",
      "Epoch 394 Batch 0 Loss 0.0002\n",
      "Epoch 394 Batch 10 Loss 0.0003\n",
      "Epoch 394 Batch 20 Loss 0.0006\n",
      "Epoch 394 Loss 0.0051\n",
      "Time taken for 1 epoch 3.763279438018799 sec\n",
      "\n",
      "Epoch 395 Batch 0 Loss 0.0002\n",
      "Epoch 395 Batch 10 Loss 0.0002\n",
      "Epoch 395 Batch 20 Loss 0.0005\n",
      "Epoch 395 Loss 0.0051\n",
      "Time taken for 1 epoch 4.011641979217529 sec\n",
      "\n",
      "Epoch 396 Batch 0 Loss 0.0002\n",
      "Epoch 396 Batch 10 Loss 0.0003\n",
      "Epoch 396 Batch 20 Loss 0.0005\n",
      "Epoch 396 Loss 0.0050\n",
      "Time taken for 1 epoch 3.5421152114868164 sec\n",
      "\n",
      "Epoch 397 Batch 0 Loss 0.0002\n",
      "Epoch 397 Batch 10 Loss 0.0002\n",
      "Epoch 397 Batch 20 Loss 0.0005\n",
      "Epoch 397 Loss 0.0049\n",
      "Time taken for 1 epoch 3.1266238689422607 sec\n",
      "\n",
      "Epoch 398 Batch 0 Loss 0.0002\n",
      "Epoch 398 Batch 10 Loss 0.0003\n",
      "Epoch 398 Batch 20 Loss 0.0005\n",
      "Epoch 398 Loss 0.0049\n",
      "Time taken for 1 epoch 4.004205942153931 sec\n",
      "\n",
      "Epoch 399 Batch 0 Loss 0.0002\n",
      "Epoch 399 Batch 10 Loss 0.0005\n",
      "Epoch 399 Batch 20 Loss 0.0007\n",
      "Epoch 399 Loss 0.0049\n",
      "Time taken for 1 epoch 3.077868938446045 sec\n",
      "\n",
      "Epoch 400 Batch 0 Loss 0.0002\n",
      "Epoch 400 Batch 10 Loss 0.0004\n",
      "Epoch 400 Batch 20 Loss 0.0005\n",
      "Epoch 400 Loss 0.0048\n",
      "Time taken for 1 epoch 3.1964683532714844 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 400\n",
    "\n",
    "encoder = Encoder(10, 1, BATCH_SIZE)\n",
    "encoder.build(tf.TensorShape([BATCH_SIZE, None, 1]))\n",
    "encoder.summary()\n",
    "\n",
    "#print(dataset)\n",
    "#print(len(list(dataset)))\n",
    "steps_per_epoch = len(list(dataset)) #//BATCH_SIZE\n",
    "#print(steps_per_epoch)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  start = time.time()\n",
    "\n",
    "  enc_hidden = encoder.initialize_hidden_state()\n",
    "  encoder.reset_states()\n",
    "  total_loss = 0\n",
    "\n",
    "  #print(dataset)\n",
    "  for (batch, (inp, targ)) in enumerate(dataset):\n",
    "    #if (batch!=0) : continue\n",
    "    #print(len(inp), len(targ))\n",
    "    batch_loss = train_step(encoder, inp, targ)\n",
    "    #print(batch_loss)\n",
    "    total_loss += batch_loss\n",
    "\n",
    "    if batch % 10 == 0:\n",
    "        print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                     batch,\n",
    "                                                     batch_loss.numpy()))\n",
    "        \n",
    "  print('Epoch {} Loss {:.4f}'.format(epoch + 1, \n",
    "                                      total_loss / steps_per_epoch))\n",
    "#    break\n",
    "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n",
    "    \n",
    "#  break\n",
    "  # saving (checkpoint) the model every 2 epochs\n",
    "#  if (epoch + 1) % 2 == 0:\n",
    "#    checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[-0.06277714]\n",
      "  [-0.09907252]\n",
      "  [-0.08114558]\n",
      "  [-0.08857042]\n",
      "  [-0.08270252]\n",
      "  [-0.08375782]\n",
      "  [-0.07982171]\n",
      "  [-0.0793016 ]\n",
      "  [-0.07626146]\n",
      "  [-0.07490337]\n",
      "  [-0.07226253]\n",
      "  [-0.07044184]\n",
      "  [-0.06795967]\n",
      "  [-0.0658704 ]\n",
      "  [-0.06343353]\n",
      "  [-0.06118023]\n",
      "  [-0.05873966]\n",
      "  [-0.05638075]\n",
      "  [-0.05392003]\n",
      "  [-0.05149257]]\n",
      "\n",
      " [[-0.07659066]\n",
      "  [-0.02768469]\n",
      "  [-0.05636895]\n",
      "  [-0.03280997]\n",
      "  [-0.04529524]\n",
      "  [-0.03210843]\n",
      "  [-0.03723919]\n",
      "  [-0.02931321]\n",
      "  [-0.0307349 ]\n",
      "  [-0.02550161]\n",
      "  [-0.02506554]\n",
      "  [-0.02123427]\n",
      "  [-0.01988661]\n",
      "  [-0.01681113]\n",
      "  [-0.01504111]\n",
      "  [-0.01240087]\n",
      "  [-0.00920677]\n",
      "  [-0.00559449]\n",
      "  [-0.00198984]\n",
      "  [ 0.00162029]]\n",
      "\n",
      " [[ 0.6440315 ]\n",
      "  [-0.1905824 ]\n",
      "  [ 0.13185883]\n",
      "  [ 0.01099408]\n",
      "  [ 0.01968634]\n",
      "  [ 0.02299213]\n",
      "  [ 0.02644908]\n",
      "  [ 0.02984834]\n",
      "  [ 0.03318954]\n",
      "  [ 0.03646588]\n",
      "  [ 0.03966999]\n",
      "  [ 0.04279494]\n",
      "  [ 0.04583418]\n",
      "  [ 0.04878128]\n",
      "  [ 0.05162919]\n",
      "  [ 0.05437195]\n",
      "  [ 0.05700374]\n",
      "  [ 0.05951786]\n",
      "  [ 0.06190956]\n",
      "  [ 0.06417251]]\n",
      "\n",
      " [[ 0.6364249 ]\n",
      "  [ 0.05836302]\n",
      "  [ 0.06906974]\n",
      "  [ 0.07190543]\n",
      "  [ 0.07339257]\n",
      "  [ 0.07478541]\n",
      "  [ 0.07602084]\n",
      "  [ 0.07709494]\n",
      "  [ 0.07800409]\n",
      "  [ 0.07874617]\n",
      "  [ 0.07931991]\n",
      "  [ 0.07972211]\n",
      "  [ 0.07995243]\n",
      "  [ 0.08000875]\n",
      "  [ 0.0798921 ]\n",
      "  [ 0.07960004]\n",
      "  [ 0.07913435]\n",
      "  [ 0.07849339]\n",
      "  [ 0.07767865]\n",
      "  [ 0.07669288]]\n",
      "\n",
      " [[ 0.4995544 ]\n",
      "  [ 0.07886171]\n",
      "  [ 0.06918061]\n",
      "  [ 0.07106388]\n",
      "  [ 0.06925666]\n",
      "  [ 0.06724215]\n",
      "  [ 0.06510341]\n",
      "  [ 0.06281281]\n",
      "  [ 0.06037354]\n",
      "  [ 0.05779111]\n",
      "  [ 0.05506968]\n",
      "  [ 0.05221534]\n",
      "  [ 0.04923487]\n",
      "  [ 0.04613245]\n",
      "  [ 0.04291403]\n",
      "  [ 0.03958821]\n",
      "  [ 0.0361613 ]\n",
      "  [ 0.03264153]\n",
      "  [ 0.02903497]\n",
      "  [ 0.02535188]]\n",
      "\n",
      " [[ 0.03120482]\n",
      "  [ 0.01573622]\n",
      "  [ 0.01378775]\n",
      "  [ 0.01003528]\n",
      "  [ 0.00606406]\n",
      "  [ 0.00209379]\n",
      "  [-0.00188994]\n",
      "  [-0.00588083]\n",
      "  [-0.00986814]\n",
      "  [-0.01384246]\n",
      "  [-0.01779544]\n",
      "  [-0.02171826]\n",
      "  [-0.02560115]\n",
      "  [-0.02943432]\n",
      "  [-0.03321147]\n",
      "  [-0.03692365]\n",
      "  [-0.04056108]\n",
      "  [-0.044119  ]\n",
      "  [-0.04758823]\n",
      "  [-0.05096245]]\n",
      "\n",
      " [[ 0.02480066]\n",
      "  [-0.07552147]\n",
      "  [-0.06119621]\n",
      "  [-0.06316972]\n",
      "  [-0.06619632]\n",
      "  [-0.06888866]\n",
      "  [-0.07144058]\n",
      "  [-0.07385927]\n",
      "  [-0.07614267]\n",
      "  [-0.07828403]\n",
      "  [-0.08028603]\n",
      "  [-0.0821417 ]\n",
      "  [-0.08385378]\n",
      "  [-0.08541921]\n",
      "  [-0.08683729]\n",
      "  [-0.08810744]\n",
      "  [-0.08923092]\n",
      "  [-0.09020551]\n",
      "  [-0.09103332]\n",
      "  [-0.09171398]]\n",
      "\n",
      " [[-0.05889001]\n",
      "  [-0.10346003]\n",
      "  [-0.08111411]\n",
      "  [-0.09334549]\n",
      "  [-0.08335865]\n",
      "  [-0.08778501]\n",
      "  [-0.08192766]\n",
      "  [-0.08318871]\n",
      "  [-0.07930869]\n",
      "  [-0.078933  ]\n",
      "  [-0.07597423]\n",
      "  [-0.07472825]\n",
      "  [-0.07217252]\n",
      "  [-0.07044351]\n",
      "  [-0.06803989]\n",
      "  [-0.06602693]\n",
      "  [-0.06365728]\n",
      "  [-0.06146562]\n",
      "  [-0.05907941]\n",
      "  [-0.05676687]]], shape=(8, 20, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tm = np.ones((20,1), dtype=np.float32) - mask\n",
    "d = list(dataset)[0]\n",
    "#print(d[0])\n",
    "t = encoder(d[0])\n",
    "#print(t)\n",
    "#print(\"-------\")\n",
    "print(t- d[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f :  (64, 20, 1)\n",
      "Model: \"encoder_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "unified_lstm_6 (UnifiedLSTM) multiple                  12        \n",
      "=================================================================\n",
      "Total params: 12\n",
      "Trainable params: 12\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "[<tf.Variable 'unified_lstm_6/Variable:0' shape=(3, 1) dtype=float32, numpy=\n",
      "array([[0.],\n",
      "       [0.],\n",
      "       [0.]], dtype=float32)>, <tf.Variable 'unified_lstm_6/Variable:0' shape=(3, 1) dtype=float32, numpy=\n",
      "array([[0.],\n",
      "       [0.],\n",
      "       [0.]], dtype=float32)>]\n",
      "---------------\n",
      "tf.Tensor(\n",
      "[[[0.0158008 ]]\n",
      "\n",
      " [[0.00468961]]\n",
      "\n",
      " [[0.01020594]]], shape=(3, 1, 1), dtype=float32)\n",
      "---------------\n",
      "<tf.Variable 'unified_lstm_6/Variable:0' shape=(3, 1) dtype=float32, numpy=\n",
      "array([[0.03419656],\n",
      "       [0.00952361],\n",
      "       [0.02121729]], dtype=float32)>\n",
      "Model: \"encoder_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "unified_lstm_6 (UnifiedLSTM) multiple                  12        \n",
      "=================================================================\n",
      "Total params: 12\n",
      "Trainable params: 12\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#BATCH_SIZE = 64\n",
    "#f = dataset.take(1)\n",
    "#print(f.shape)\n",
    "f = next(iter(dataset))\n",
    "#print(f)\n",
    "print(\"f : \", f.shape)\n",
    "#print(\"f : \", f.shape, f)\n",
    "#f = tf.zeros((BATCH_SIZE, 2, 10))\n",
    "#f = tf.ones((BATCH_SIZE, 1, 1))\n",
    "\n",
    "#print(list(f))\n",
    "#print(\"f : \", f.shape, f)\n",
    "#print(\"f2 : \", f2.shape, f2)\n",
    "encoder = Encoder(1, 3) # BATCH_SIZE)\n",
    "#print(encoder.lstm.input_spec[0])\n",
    "#encoder.reset_states(encoder.initialize_hidden_state());\n",
    "encoder.build(tf.TensorShape([3,None,1]))\n",
    "\n",
    "\"\"\" \n",
    "    shape = (A, B, C)\n",
    "    A : BATCH_SIZE (nombre de lot envoyer en meme temps)\n",
    "    B : Nombre de dpliage\n",
    "    C : Nombre d'input \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#encoder.build(tf.TensorShape([1,None,1]))\n",
    "#encoder.build([tf.TensorShape([5,1,1]), tf.TensorShape([5,1])])\n",
    "encoder.summary()\n",
    "print(encoder.lstm.states)\n",
    "#encoder.reset_states()\n",
    "f = tf.constant([[[1.]],[[0.2]],[[0.5]]], dtype=tf.float32)\n",
    "sample_output = encoder(f) #, sample_hidden)\n",
    "print(\"---------------\")\n",
    "print(sample_output)\n",
    "print(\"---------------\")\n",
    "print(encoder.lstm.states[1])\n",
    "\n",
    "\"\"\"encoder.lstm.reset_states()\n",
    "sample_output = encoder(f) #, sample_hidden)\n",
    "print(\"---------------\")\n",
    "print(sample_output)\n",
    "print(\"---------------\")\n",
    "print(encoder.lstm.states[1])\"\"\"\n",
    "\n",
    "encoder.summary()\n",
    "\n",
    "#sample_hidden = encoder.initialize_hidden_state()\n",
    "#sample_hidden = tf.zeros((BATCH_SIZE,1))\n",
    "#print(sample_hidden)\n",
    "#sample_output, sample_hidden = encoder(f) #, sample_hidden)\n",
    "#sample_output = encoder(f) #, sample_hidden)\n",
    "#encoder.summary()\n",
    "\n",
    "#print(encoder.gru.dynamic)\n",
    "#print(\"---------------\")\n",
    "#sample_output, sample_hidden = encoder(f2, sample_hidden)\n",
    "#print(\"---------------\")\n",
    "#print(sample_output)\n",
    "#print(sample_output, sample_hidden)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
