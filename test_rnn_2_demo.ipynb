{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install packaging\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from packaging import version\n",
    "import time\n",
    "\n",
    "assert(version.parse(tf.__version__) >= version.parse(\"2.0.0-aplha\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generate_serie(size, step) :\n",
    "    maxT = size*step\n",
    "    t = np.arange(0, maxT, step)\n",
    "#    return (np.sin(t+np.cos(t*0.31))).astype(np.float32)\n",
    "    return (np.sin(t+np.sin(t*.31)) * np.sin(t / 3.3485)).astype(np.float32)\n",
    "#    return (np.sin(t+np.cos(t)) + .34158*np.sin(t * 3.3485)).astype(np.float32)\n",
    "#return (t * np.sin(t)/maxT + .3*np.sin(t * 3.3)).astype(np.float32)\n",
    "\n",
    "def split(arr, *count) :\n",
    "    total = sum(count)\n",
    "    p0 = 0\n",
    "    for i in count :\n",
    "        p1 = p0 + i\n",
    "        yield arr[int(len(arr)*p0/total):int(len(arr)*p1/total)]\n",
    "        p0 = p1\n",
    "    \n",
    "    \n",
    "np.random.seed(42)\n",
    "\n",
    "N_STEPS = n_steps = 50\n",
    "data = generate_serie(14001, .18)\n",
    "data = [(data[i:i+n_steps], data[i+1:i+n_steps+1]) for i in range(len(data)-n_steps-1)] \n",
    "np.random.shuffle(data)\n",
    "\n",
    "#plt.plot(data[1][0])\n",
    "#plt.plot(data[2][0])\n",
    "#plt.plot(data[3][0])\n",
    "#plt.show()\n",
    "\n",
    "spt_data = np.reshape([data[i][0] for i in range(len(data))], (-1, n_steps, 1))\n",
    "spt_lbl = np.reshape([data[i][1] for i in range(len(data))], (-1, n_steps, 1))\n",
    "\n",
    "train_size = 80\n",
    "valid_size = 15\n",
    "test_size = 5\n",
    "\n",
    "[train, valid, test] = zip(split(spt_data, train_size, valid_size, test_size), \n",
    "                           split(spt_lbl, train_size, valid_size, test_size))\n",
    "\n",
    "plt.plot(train[0][1])\n",
    "plt.plot(train[0][2])\n",
    "plt.plot(train[0][3])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "  def __init__(self, hidden1, enc_units, batch_sz) : #, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "    super(Encoder, self).__init__()\n",
    "    self.hidden1 = hidden1\n",
    "    self.enc_units = enc_units\n",
    "    self.batch_sz = batch_sz\n",
    "    #self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    #self.inputi = tf.keras.Input(shape=(1,))\n",
    "    #self.input_shape = tf.TensorShape([None,1])\n",
    "    self.lstm = tf.keras.layers.LSTM(self.enc_units,\n",
    "                                    return_sequences=True,\n",
    "                                    #return_state=True,\n",
    "                                    stateful=True,\n",
    "                                    #activation=\"selu\",\n",
    "                                    #activation=\"linear\",\n",
    "                                    #recurrent_activation=\"selu\",  \n",
    "                                    recurrent_initializer='glorot_uniform')\n",
    "    self.dense = tf.keras.layers.Dense(self.enc_units,\n",
    "                                    activation=\"linear\")\n",
    "\n",
    "    #self.gru = tf.keras.layers.RNN(\n",
    "    #    tf.keras.layers.GRUCell(self.enc_units,\n",
    "    #                               recurrent_initializer='glorot_uniform'),\n",
    "    #   return_sequences=True,\n",
    "    #   return_state=True\n",
    "    #)\n",
    "    \n",
    "  def call(self, x, initial_state=None): #, hidden):\n",
    "    #print(x, initial_state)\n",
    "    #x2 = self.inputi(x)\n",
    "    #print(x2)\n",
    "    if (initial_state!=None) :\n",
    "        self.lstm.reset_states(initial_state)\n",
    "    \n",
    "    #output = self.lstm(x) #, initial_state = hidden)\n",
    "    x = self.lstm(x) #, initial_state = hidden)\n",
    "    output = self.dense(x)\n",
    "    #output, self.state = self.lstm(x, self.state) #, initial_state = hidden)\n",
    "    return output #, state\n",
    "\n",
    "  #def reset_states(self) :\n",
    "  #  self.lstm.reset_states()\n",
    "\n",
    "  def reset_states(self, initial_state=None) :\n",
    "    #print(self.lstm.input_spec)\n",
    "    self.lstm.reset_states(initial_state)\n",
    "\n",
    "  def initialize_hidden_state(self):\n",
    "    return tf.zeros((self.batch_sz, self.enc_units))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "EPOCHS = 4\n",
    "\n",
    "encoder = Encoder(10, N_STEPS, BATCH_SIZE)\n",
    "encoder.build(tf.TensorShape([BATCH_SIZE, None, 1]))\n",
    "encoder.summary()\n",
    "encoder.compile(optimizer=\"Adam\", loss=\"MSE\")\n",
    "#print(len(train[0]))\n",
    "#print(len(train[0])//BATCH_SIZE)\n",
    "#print(len(train[0])//BATCH_SIZE*BATCH_SIZE)\n",
    "#print(len(valid[0]))\n",
    "#print(len(valid[0])//BATCH_SIZE)\n",
    "#print(len(valid[0])//BATCH_SIZE*BATCH_SIZE)\n",
    "tbs = len(train[0])//BATCH_SIZE*BATCH_SIZE\n",
    "vbs = len(valid[0])//BATCH_SIZE*BATCH_SIZE\n",
    "history = encoder.fit(train[0][:tbs], train[1][:tbs], epochs=EPOCHS, validation_data=(valid[0][:vbs], valid[1][:vbs]), batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(history)\n",
    "#print(history.history)\n",
    "print(history.history.keys())\n",
    "\n",
    "plt.plot(history.history['loss'], label=\"loss\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
