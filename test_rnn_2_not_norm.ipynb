{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install packaging\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from packaging import version\n",
    "import time\n",
    "\n",
    "assert(version.parse(tf.__version__) >= version.parse(\"2.0.0-aplha\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generate_serie(size, step) :\n",
    "    maxT = size*step\n",
    "    t = np.arange(0, maxT, step)\n",
    "#    return (np.sin(t+np.cos(t*0.31))).astype(np.float32)\n",
    "    return ((np.sin(t+np.sin(t*.31)) * np.sin(t /10 / 3.3485)).astype(np.float32)+1)*3\n",
    "#    return (np.sin(t+np.cos(t)) + .34158*np.sin(t * 3.3485)).astype(np.float32)\n",
    "#return (t * np.sin(t)/maxT + .3*np.sin(t * 3.3)).astype(np.float32)\n",
    "\n",
    "def split(arr, *count) :\n",
    "    total = sum(count)\n",
    "    p0 = 0\n",
    "    for i in count :\n",
    "        p1 = p0 + i\n",
    "        yield arr[int(len(arr)*p0/total):int(len(arr)*p1/total)]\n",
    "        p0 = p1\n",
    "    \n",
    "    \n",
    "np.random.seed(42)\n",
    "\n",
    "N_STEPS = n_steps = 50\n",
    "data = generate_serie(14001, .18)\n",
    "data = [(data[i:i+n_steps], data[i+1:i+n_steps+1]) for i in range(len(data)-n_steps-1)] \n",
    "np.random.shuffle(data)\n",
    "\n",
    "#plt.plot(data[1][0])\n",
    "#plt.plot(data[2][0])\n",
    "#plt.plot(data[3][0])\n",
    "#plt.show()\n",
    "\n",
    "spt_data = np.reshape([data[i][0] for i in range(len(data))], (-1, n_steps, 1))\n",
    "spt_lbl = np.reshape([data[i][1] for i in range(len(data))], (-1, n_steps, 1))\n",
    "\n",
    "train_size = 50\n",
    "valid_size = 40\n",
    "test_size = 10\n",
    "\n",
    "[train, valid, test] = zip(split(spt_data, train_size, valid_size, test_size), \n",
    "                           split(spt_lbl, train_size, valid_size, test_size))\n",
    "\n",
    "plt.plot(train[0][1])\n",
    "plt.plot(train[0][2])\n",
    "plt.plot(train[0][3])\n",
    "plt.show()\n",
    "\n",
    "train = tf.data.Dataset.from_tensor_slices((train[0], train[1]))\n",
    "valid = tf.data.Dataset.from_tensor_slices((valid[0], valid[1]))\n",
    "test = tf.data.Dataset.from_tensor_slices((test[0], test[1]))\n",
    "#train = train.batch(64, True)\n",
    "#valid = valid.batch(64, True)\n",
    "#test = test.batch(64, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "  def __init__(self, hidden1, enc_units, batch_sz) : #, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "    super(Encoder, self).__init__()\n",
    "    self.hidden1 = hidden1\n",
    "    self.enc_units = enc_units\n",
    "    self.batch_sz = batch_sz\n",
    "\n",
    "    self.lstm = tf.keras.layers.LSTM(self.hidden1,\n",
    "                                    return_sequences=True,\n",
    "                                    #return_state=True,\n",
    "                                    stateful=not True,\n",
    "                                    #activation=\"relu\",\n",
    "                                    #activation=\"selu\",\n",
    "                                    #activation=\"linear\",\n",
    "                                    #recurrent_activation=\"selu\",  \n",
    "                                    recurrent_initializer='glorot_uniform')\n",
    "    self.dense = tf.keras.layers.Dense(self.enc_units,\n",
    "                                    activation=\"linear\")\n",
    "\n",
    "    \n",
    "#  def call(self, x, initial_state=None): #, hidden):\n",
    "  def call(self, x) :\n",
    "    mean = tf.keras.backend.mean(x, [1], True)\n",
    "    var = tf.keras.backend.var(x, [1], True)\n",
    "    x = (x - mean) / tf.keras.backend.sqrt(var)\n",
    "    \n",
    "    #return x\n",
    "    x = self.lstm(x) #, initial_state = hidden)\n",
    "    x = self.dense(x)\n",
    "    x = x * tf.keras.backend.sqrt(var) + mean\n",
    "    return x\n",
    "\n",
    "#  def reset_states(self) :\n",
    "#    self.lstm.reset_states()\n",
    "\n",
    "#  def reset_states(self, initial_state=None) :\n",
    "#    #print(self.lstm.input_spec)\n",
    "#    self.lstm.reset_states(initial_state)\n",
    "\n",
    "#  def initialize_hidden_state(self):\n",
    "#    return tf.zeros((self.batch_sz, self.enc_units))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "encoder = Encoder(30, 1, BATCH_SIZE)\n",
    "encoder.build(tf.TensorShape([BATCH_SIZE, None, 1]))\n",
    "encoder.summary()\n",
    "encoder.compile(optimizer=\"Adam\", loss=\"MSE\", metrics=['accuracy'])\n",
    "encoder(tf.keras.Input(shape=(50, 1)))\n",
    "print(\"stateful\", encoder.stateful, encoder.state_updates)\n",
    "print(\"encoder\", encoder.input_shape, encoder.output_shape)\n",
    "#print(\"lstm\", encoder.lstm.input_shape, encoder.lstm.output_shape)\n",
    "#print(\"dense\", encoder.dense.input_shape, encoder.dense.output_shape)\n",
    "\n",
    "#val, m, m0, m1, m2 = encoder.predict(test.batch(BATCH_SIZE, True))\n",
    "#(val0, val1, m0, m1, m2, m3, m4, m5) = encoder.predict(test.batch(BATCH_SIZE, True))\n",
    "#val, v0, v1, v2 = encoder.predict(test.batch(BATCH_SIZE, True))\n",
    "val = encoder.predict(test.batch(BATCH_SIZE, True))\n",
    "\n",
    "#print(v0)\n",
    "#print(v1)\n",
    "#print(v2)\n",
    "#print(\"m0\", m0)\n",
    "#print(\"m1\", m1)\n",
    "#print(\"m2\", m2)\n",
    "#print(\"m3\", m3)\n",
    "#print(\"m4\", m4)\n",
    "#print(\"m5\", m5)\n",
    "\n",
    "plt.figure(figsize=(15.0,10.0))\n",
    "plt.plot(np.zeros(50), color='k')\n",
    "\n",
    "colors = ['b','g','r']\n",
    "for i in range(0,3) :\n",
    "    plt.plot(list(test)[i][0], label=\"s0_\" + str(i), linestyle=':', color=colors[i])\n",
    "#    plt.plot(list(test)[i][1], label=\"s1_\" + str(i))\n",
    "    plt.plot(val[i], label=\"p_\" + str(i), linestyle='-', color=colors[i])\n",
    "#    plt.plot(val0[i], label=\"p_\" + str(i), linestyle='-')\n",
    "#    plt.plot(val1[i], label=\"p_\" + str(i), linestyle='--')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64 #*8\n",
    "\n",
    "#encoder = Encoder(10, N_STEPS, BATCH_SIZE)\n",
    "encoder = Encoder(10, 1, BATCH_SIZE)\n",
    "encoder.build(tf.TensorShape([BATCH_SIZE, None, 1]))\n",
    "encoder.summary()\n",
    "encoder.compile(optimizer=\"Adam\", loss=\"MSE\", metrics=['accuracy'])\n",
    "encoder(tf.keras.Input(shape=(50, 1)))\n",
    "print(\"stateful\", encoder.stateful, encoder.state_updates)\n",
    "print(\"encoder\", encoder.input_shape, encoder.output_shape)\n",
    "#print(\"lstm\", encoder.lstm.input_shape, encoder.lstm.output_shape)\n",
    "#print(\"dense\", encoder.dense.input_shape, encoder.dense.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = 12*5\n",
    "EPOCHS = 8\n",
    "\n",
    "#encoder.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.MeanSquaredError())\n",
    "#print(len(train[0]))\n",
    "#print(len(train[0])//BATCH_SIZE)\n",
    "#print(len(train[0])//BATCH_SIZE*BATCH_SIZE)\n",
    "#print(len(valid[0]))\n",
    "#print(len(valid[0])//BATCH_SIZE)\n",
    "#print(len(valid[0])//BATCH_SIZE*BATCH_SIZE)\n",
    "#tbs = len(train[0])//BATCH_SIZE*BATCH_SIZE\n",
    "#vbs = len(valid[0])//BATCH_SIZE*BATCH_SIZE\n",
    "\n",
    "#a = encoder(train[0][:8])\n",
    "#print(a)\n",
    "#history = encoder.fit(train, epochs=EPOCHS) #, batch_size=BATCH_SIZE, shuffle=False)\n",
    "#history = encoder.fit(train[0][:tbs], train[1][:tbs], epochs=EPOCHS, batch_size=BATCH_SIZE)\n",
    "history = encoder.fit(train.batch(BATCH_SIZE, True), epochs=EPOCHS, validation_data=valid.batch(BATCH_SIZE, True), shuffle=False) # , batch_size=BATCH_SIZE\n",
    "#history = encoder.fit(train.batch(BATCH_SIZE, True), epochs=EPOCHS, validation_data=valid.batch(BATCH_SIZE, True), callbacks=[ResetCallback()], shuffle=False) # , batch_size=BATCH_SIZE\n",
    "#history = encoder.fit(train.batch(64, True), epochs=EPOCHS, validation_data=valid.batch(64, True), callbacks=[ResetCallback()], shuffle=False) # , batch_size=BATCH_SIZE\n",
    "#history = encoder.fit(train[0][:tbs], train[1][:tbs], epochs=EPOCHS, validation_data=(valid[0][:vbs], valid[1][:vbs]), batch_size=BATCH_SIZE)\n",
    "#a = encoder(train[0][:8])\n",
    "#print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(history)\n",
    "#print(history.history)\n",
    "print(history.history.keys())\n",
    "\n",
    "plt.plot(history.history['loss'], label=\"loss\")\n",
    "plt.plot(history.history['val_loss'], label=\"val_loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.plot(history.history['accuracy'], label=\"accuracy\")\n",
    "plt.plot(history.history['val_accuracy'], label=\"val_accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = encoder.predict(test.batch(BATCH_SIZE, True))\n",
    "val = encoder.predict(val)\n",
    "val = encoder.predict(val)\n",
    "#val = encoder.predict(val)\n",
    "#val = encoder.predict(val)\n",
    "#val = encoder.predict(val)\n",
    "\n",
    "plt.figure(figsize=(15.0,10.0))\n",
    "for i in range(0,3) :\n",
    "    plt.plot(list(test)[i][0], label=\"s0_\" + str(i), linestyle=':')\n",
    "    plt.plot(list(test)[i\n",
    "                       ][1], label=\"s1_\" + str(i))\n",
    "    plt.plot(val[i], label=\"p_\" + str(i), linestyle='dashed')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
